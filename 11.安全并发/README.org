* 安全并发  
** 通用概念
   并发(Concurrency)的概念很容易和并行(Parallelism)混淆, 事实上它们是不同的概念.

   谷歌著名工程师罗布派克(Rob Pike)说过: "并发就是 *同时应对(Dealing With)* 多件
   事情的能力, 并行是 *同时执行(Doing)* 多件事情的能力".

   将任务分配在不同的时间片内交替完成就是 *并发, 关注点在于任务的切分, 这是一种
   逻辑架构、一种能力*. 每个单位都是事情执行的个体, 相互无影响, 各自独立工作, 这
   就是 *并行, 关注点在于同时执行, 这是具体的实施状态*. 并发并不要求一定要并行,
   利用并并发可以制造出并行的假象.

   在实际编程中, 对任务进行分解才是重点, 一旦将任务分解正确, 到了执行层面, 并行
   就会自然发生, 也容易保证程序的正确性. 如何分解任务是并发设计要解决的问题, 所
   以, 通过更关注并发而非并行.

   使用并发主要出于 2 个主要原因: *性能* 和 *容错*.

   随着多核计算机的普及, 为了利用日益增长的计算能力, 就必须要编写并发程序. 并发
   编程越来越受重视, 甚至可能成为一种新的编程范式, Go 语言的横空出世就证明了这一
   点. 另外, 并发编程还可以将程序分为不同的功能区域, 让程序更容易理解和测试, 从
   而减少程序出错的可能性.

   在计算机中, 通常使用一些独立的运行实体对并发进行支持, 分为如下两类:
   - 操作系统提供的进程和线程
   - 编程语言内置的用户级线程

*** 多进程和多线程
    进程是资源分配的最小单元, 线程是程序执行时的最小单元.

    从操作系统的角度来看, 进程代表操作系统分配的内存、CPU 时间片等资源的基本单位,
    它为程序提供基本的运行环境. 不同的应用程序可以按业务划分为不同的进程. 从用户
    的角度来看, 进程代表运行中的应用程序, 它是动态条件下由操作系统维护的资源管理
    实体, 而非静态的应用程序文件. 每个进程都享有自己独立的内存单元, 从而极大地提
    高了程序的运行效率.

    可以使用多进程来提供并发, eg: Mater-Worker 模式, 由 Master 进程来管理 Worker
    子进程, Worker 子进程执行任务. Master 和 Worker 之间通常使用 Socket 来进行进
    程间通信(IPC). 这样的好处就是具有极高的健壮性, 当某个 Worker 子进程出现问题
    时, 不会影响到其他子进程. 但缺点也非常明显, 其中最让人诟病的是进程会占用相当
    可观的系统资源. 除此之外, 进程还有切换复杂、CPU 利用率低、创建和销毁复杂等缺
    点.

    为了寻求比进程更小的资源占用, 线程应运而生. 线程是进程内的实体, 它无法独立存
    在, 必须依靠进程, 线程的资源资源都来源于进程, 包括内存. 每个进程至少拥有一个
    线程, 这个线程就是主线程. 每个进程也可以生成若干个线程来并发执行多任务, 但只
    能有一个主线程, 线程和线程之间可以共享同一个进程内的资源. 一个线程也可以创建
    或销毁另一个线程, 所以线程会有创建、就绪、运行、阻塞和死亡 5 种状态. 每个线
    程也有自己独享的资源, eg:线程栈. 线程和进程一样, 都受操作系统内核的调度. 线
    程拥有进程难以企及的优点, eg: 占用内存少, 切换简单, CPU 利用率搞, 创建/销毁
    简单、快速等. 线程的缺点也是非常明显的, eg: 编程相当复杂, 调试困难等. 正是由
    于这些缺点, 导致多线程并发编程成为众多开发者心中的痛.

*** 事件驱动、异步回调和协程
    多线程虽然比多进程更省资源, 但其依然存在昂贵的系统内核调度代价. 互联网的发展
    让这个问题更加突出. 在服务器领域有一个非常出名的 *C10K* 问题, 主要是指单台服
    务器要同时处理 10K 量级的并发连接, 解决此问题最直接的就是多进程(线程)并发,
    每个进程(线程)处理一个连接. 但是, 这种处理方式显然是有问题的, 因为服务器根本
    没有这么多资源可以分配给如此多的进程(线程).

    为了解决 C10K 问题, *事件驱动编程* 应运而生, 最知名的就是 Linux 退出的
    *epoll* 技术. 事件驱动也可以称为事件轮询, 它的优点在于编程更加容易, 不用做并
    发设计的考虑, 不需要引入锁, 不需要考虑内部调度, 只需要依赖于事件, 最重要的是
    不会阻塞. 所以它可以很方便地和编程语言相集成, eg: Node.js, 也就是第一个事件
    驱动编程模型语言. 在 Node.js 中, 仅仅使用单线程就可以拥有强大的并发处理能力,
    其力量来源就是 *事件驱动* 和 *异步回调(Callback)*. 通过内置的事件循环机制,
    不断地从事件队列中查询是否有事件发生, 当读取到时间时, 就会调用和此事件关联的
    回调函数, 整个过程是非阻塞的.

    事件驱动和回调函数虽然解决了 C10K 的问题, 但是对于开发者来说还远远没有那么完
    美. 问题就出在回调函数上面, 如果编写业务比较复杂的代码, 开发者将陷入 "*回调
    地狱(Callback Hell)*" 中, 代码中充斥着各种回调嵌套, 很快就会变成一团乱麻. 回
    调函数的这种写法, 并不符合人类的思维直觉, 所以使用起来比较痛苦.

    为了避免 "回调低于", 不停地有新方案被提出, eg: *Promise* 和 *Future*, 这两种
    方案从不同的角度来处理回调函数. Promise 站在任务处理者的角度, 将异步任务完成
    或失败的状态标记到 Promise 对象中. Future 则站在任务调用者的角度, 来检测任务
    是否完成, 如果完成则直接获取结果, 如果未完成则阻塞直到获取到结果, 或者编写回
    调函数避免阻塞, 根据相应地完成状态执行此回调函数. 虽然 Promise 和 Future 可
    以进一步缓解回调函数的问题, 但它们还是不够完美, 代码中依然充斥着各种冗余.

    为了进一步完善基于事件驱动的编程体验, 一种叫作 *协程* 的解决方案浮出水面. 协
    程的概念很古老, 甚至可以追溯到 20 世纪 60 年代的 COBOL 语言, 但是因为时代使
    然, 协程并未称为像线程那样的通用编程元素. 然而, 随着事件编程的兴起, 协程又有
    了用武之地.

    协程为协同任务提供了一种抽象, 这种抽象本质上就是控制流的出让和恢复. 协程的这
    种机制, 正好符合现实世界中人类异步处理实物的直觉. eg: 程序员可以暂停自己写代
    码的过程, 进行场景切换, 去参加产品经理组织的会议, 当会议结束后, 再切回之前的
    场景继续编写代码. 虽然处理了不同的事件, 但对于程序员来说, 都是顺序执行的. 可
    以看出, 协程和事件驱动属于绝配. 当事件来临时, 出让当前的控制权, 切换场景, 完
    成该事件, 然后再切换回之前的场景, 恢复之前的工作. 如果说事件驱动编程和异步回
    调是站在开发者的角度来进行编程的. 开发者将自身代入各事件中, 看上去就是顺序执
    行的. 总的来说, 协程可以让开发者用写同步(顺序)代码的方式编写可异步执行的代码.

    在现代编程语言中, 实现协程的方法有很多, 但其中的区别只在于是否有适合的应用场
    景. 场景的有 Go 语言的 *go 程(goroutines)*, Erlang 语言的 *轻量级线程(LWP)*.
    另外, 像 Python、Ruby、JavaScript 这样的语言也实现了协程, 当然 Rust 语言也支
    持协程. 协程是以线程为龙骑的, 协程的特点是内存占用比线程更小, 上下文切换的开
    销更小、没有昂贵的系统内核调度, 这也意味着协程的运行效率更加高效. 协程非常轻
    量, 也被称为用户态线程, 所以可大量使用. 但协程也不是 "银弹", 它虽然充分挖掘
    了单线程的利用率, 在单线程下可以处理高并发 I/O, 但却无法利用多核.

    当然, 可以将协程和多线程配合使用, 来充分利用多核. 但是, 从单线程迁移到多线程
    并不会只带来好处, 它也会带来更多的风险.

*** 线程安全
    线程其实是对底层硬件运行过程的直接抽象, 这种抽象方式既有优点又有缺点. *优点*
    在于很多编程语言都对其提供了支持, 并且没有对其使用方式加以限制, 开发者可以自
    由地实现多线程并发程序, 充分利用多核. *缺点* 包含两个方面: 一方面, 线程的调
    度完全由系统内核来控制, 完全随机, 这就导致多个线程的运行顺序是完全无法预测的,
    有可能产生奇怪的结果; 另一方面, 编程正确的多线程并发程序对开发者的要求太高,
    对多线程编程没有充足知识储备的开发者很容易写出满是 Bug 的多线程代码, 并且还
    很难重现和调试.

    多线程存在问题主要是因为资源共享, eg:　共享内存、文件、数据库等. 实际上, 只
    有当一个或多个线程对这些资源进行写操作时才会出现问题, 如果只读不写, 资源不会
    发生变化, 自然也不会存在安全问题. 假如一个方法、数据结构或库在多线程环境中不
    会出现任何问题, 则可以称之为 *线程安全*.

    所以, 多线程编程的重点就是如何写出线程安全的代码.

**** 竞态条件与临界区
     要想写出线程安全的代码, 必须先了解安全的边界在哪里.

     在单线程环境中, ~unsafe_seq()~ 函数不会有任何问题, 但是将其放到多线程环境中,
     则会有问题. 实际上, ~V+=1~ 操作上在运行过程中并非单个指令, 而是可以分为三
     步:
     1) 从内存中将 ~V~ 的初始值放入寄存器中
     2) 将寄存器中的 ~V~ 的值加 1.
     3) 将加 1 后的值写入内存.

     这三步操作无法保证在同一个线程中被一次执行完成. 因为系统内核调度的存在, 很
     有可能在线程 A 执行第二步操作之后, 从线程 A 切换到了线程 B, 而线程 B 此时并
     不知道线程 A 已经执行了第一步操作, 它又重复将 ~V~ 的初始值放入寄存器中, 当
     又切换回线程 A 后, 线程 A 会继续执行第三步操作, 此时就从寄存器中读取了错误
     的值.

     这种常见的并发安全问题, 叫作 *竞态条件(Race Condition)*. 当某个计算的正确性
     取决于多个线程交替执行的顺序时, 就会产生竞态条件. 也就是说, 想计算出正确的
     结果, 全靠运气. 最常见的竞态条件类型是: "*读取-修改-写入*" 和 "*先检查后执
     行*" 操作. 代码 11-1 展示的就是 "读取-修改-写入" 竞态条件; 而 "先检查后执行
     " 竞态条件则出现在需要判断某个条件为真之后才采取相应地动作时. 产生竞态条件
     的区域, 就叫做 *临界区*.

     在代码清单 11-1 中展示的代码也同时引起了 *数据竞争(Data Race)*. "数据竞争"
     这个术语很容易和竞态条件相混淆. 当一个线程写一个变量而另一个线程读这个变量
     时, 如果这两个线程没有进行同步, 则会发生数据竞争. 因为竞态条件的存在, 读操
     作很可能在操作之前就完成了, 那么读到的数据就是错误的.
     *并非所有的竞态条件都是数据竞争, 也并非所有的数据竞争都是竞态条件*.

     简单来说, 当有多个线程对同一个变量同时进行读写操作, 且至少有一个线程对该变
     量进行写操作时, 则会发生数据竞争. 也就是说, 如果所有的线程都是读操作, 则不
     会发生数据竞争. 数据竞争的后果是早成该变量的值不可知, 多线程程序的运行结果
     将完全不可预测, 甚至直接崩溃.

     11-2 用于转账操作的函数(伪代码):
     #+begin_example
       trans1(amount, account_from, account_to) {
           if (account_from.balance < amount) return FALSE;
           account_to.balance += amount;
           account_from.balance -= amount;
           return TRUE;
       }
     #+end_example
     
     在多线程环境中, 这个伪代码示例既包含了竞态条件, 又包含了数据竞争, 转账结果
     将不可预测. 为了解决该问题, 采用某种同步操作, eg: 使用互斥量(Mutex)或某种禁
     用中断操作的事务, 将包含数据竞争的操作变为原子性操作.
     
     11-3 改进转帐操作的函数:
     #+begin_example
       trans2(amount, account_from, account_to) {
           atomic { bal = account_from.balance; }
           if (bal < amount) return FALSE;
           atomic { account_to.balance += amount; }
           atomic { account_from.balance -= amount; }
           return TRUE;
       }
     #+end_example

     使用 atomic 块表示将其范围内的操作变为原子性的某种手段. 总之, 现在数据竞争
     被消除了. 但还存在竞态条件, 不同的线程依然可以乱序执行代码第 4 行和第 5 行
     的操作. 这个交易函数 ~trans2()~ 的正确性, 在不同的线程执行顺序下, 会出现不
     同的结果. 所以还需要继续对其改进.

     11-4 继续改进转账操作的函数
     #+begin_example
       trans3(amount, account_from, account_to) {
           atomic {
               if (account_from.balance < amount) return FALSE;
               account_to.balance += amount;
               account_from.balance -= amount;
               return TRUE;
           }
       }
     #+end_example

     在 ~trans3()~ 函数中, 通过 atomic 块将 整个函数的执行过程赋予原子性, 这样就
     完全消除了数据竞争和竞态条件. 可以看出, *消除竞态条件的关键在于判断出正确的
     临界区*.

     还可以对其进一步改进, 创建一个有数据竞争但无竞态条件的函数.
     11-5 进一步改进转账操作的函数
     #+begin_example
       trans4(amount, account_from, account_to) {
           account_from.activity = true;
           account_to.activity = true;
           atomic {
               if (account_from.balance < amount) return FALSE;
               account_to.balance += amount;
               account_from.balance -= amount;
               return TRUE;
           }
       }
     #+end_example
     
     在 ~trans4()~ 函数中增加了两行伪代码, 如第二行和第三行所示, 这两行代码表示
     这两个账号上会出现某些状态变更的行为. 这两行代码会出现数据竞争, 但不存在竞
     态条件. 但这里的数据竞争并不会影响到交易行为的正确性, 所以是无害的.

     通过上面的 4 段伪代码, 刻意区分了数据竞争和竞态条件之间的区别. 在多线程编程
     中, 数据竞争是最常见、最严重、最难调试的并发问题之一, 可能会引起崩溃会内存
     不安全.

     接下来看看 Rust 多线程代码实际产生竞态条件和数据竞争问题的例子(11-6)

     正常情况下, 对该段代码进行编译执行, 期待的数据结果是 main 主线程和 child 子
     线程一共输出 0 ~ 20 的数字. 但实际执行多次会看到不同的输出结果, 基本会出现
     以下两种情况:
     - 在 main 主线程输出的结果中会莫名其妙地少一位, 并不是 0 ~ 10 的连续值
     - child 子线程输出的结果和 main 主线程输出的结果有重复

     可以看出, 该段代码在多线程环境中的行为和结果完全无法预测, 完全无法保证正确
     性.

**** 同步、互斥和原子类型
     综上所述, 产生竞态条件主要是因为线程乱序执行, 发生数据竞争主要是因为多线程
     同时对桶一块内存进行读写. 那么, 要消除竞态条件, 只需要保证线程按指定顺序来
     访问即可. 要避免数据竞争, 只需要保证相关数据结构操作的原子性即可. 所以, 很
     多编程语言都通过提供同步机制来消除竞态条件, 使用互斥和原子类型来避免数据竞
     争.

     同步是指保证多线程按指定顺序执行的手段. 互斥是指用一时刻只允许单个线程对临
     界资源进行访问, 对其他线程具有排他性, 线程之间的关系表示为互斥. 而原子类型
     是指修改临界数据结构的内部实现, 确保对它们做任何更新, 在外界原来都是原子性
     的, 不可中断.

     通常可以使用 *锁*, *信号量(Semaphores)*, *屏障(Barrier)* 和 *条件变量
     (Condition Variable)* 机制来实现同步. 根据不同的并发场景分为很多不同类型的
     锁, 有互斥锁(Mutex)、读写锁(RwLock)和自旋锁(Spinlock)等. 锁的作用是可以保护
     临界区, 同时达到同步和互斥的效果. 不同的锁表现不同, 比如互斥锁, 每次只允许
     单个线程访问临界资源; 读写锁可以同时支持多核线程读或单个线程写; 自旋锁和互
     斥锁类似, 但当获取锁失败时, 它不会让线程睡眠, 而是不断地轮询直到获取成功.

     *信号量* 可以在线程间传递信号, 也叫作信号灯, 它可以为资源访问进行计数. 信号
     量是一个非负整数, 所有通过它的线程都会将该整数 -1, 如果信号量为 0, 那么其他
     线程只能等待. 当线程执行完毕离开临界区时, 信号量会再次 +1. 当信号量只允许设
     置 0 和 1 时, 效果相当于互斥锁.

     *屏障* 可以让一系列线程在某个指定的点进行同步. 通过让参数指定屏障区域的线程
     等待, 知道所有参与线程都到达指定的点. 而 *条件变量* 用来自动阻塞一个线程,
     直到出现指定的条件, 通常和互斥锁配合使用.

     通过一些锁机制, eg: 互斥锁, 也可以用来避免数据竞争. 本质上, 是通过锁来保护
     指定区域的原子性的. 有些语言也提供了原子类型来保证原子性, eg: Java、C++ 以
     及 Rust. 具有原子性的操作一定是不可分割的, 要么全部完成, 要么声明都不做. 原
     子类型使用起来简单, 但其背后的机制缺一点也不简单, 了解其背后的机制有助于更
     好地使用原子类型.
     
**** 原子类型与多线程内存模型
     在计算机中程序需要经过 CPU、CPU 多级缓存和内存等协同工作才能顺利执行, 在这
     种体系结构之下, 如果是多核系统, 其中一个 CPU 核心修改了变量, 那么如果通知其
     他核心是一个重要的问题. 并且为了提高性能, 现代处理器和编程语言的编译器都对
     程序进行了极度优化, eg: *乱序执行* 和 *指令重排*, 所以机器并非按照实际编写
     的那样来执行. 在多线程编程中, 只有保持顺序一致性, 才能保证程序的正确性. 所
     谓 *顺序一致性*, 主要约定了 2 件事:
     - 在单线程内部指令都是按程序确定的顺序来执行的
     - 多线程程序在执行过程中虽然是交替执行的, 但从全局来看, 也是按某种确定的顺
       序来执行的.

     显然, 在硬件层面并没有支持顺序一致性, 所以需要编程语言和计算机系统(包括编译
     器、CPU 等)  之间达成 "契约", 该契约规定了多线程访问同一个内存位置时的语义,
     以及某个线程对内存位置的更新何时才能被其他线程看到. 这个契约就是 *多线程内
     存模型*. 通过该内存模型, 程序员就可以使用编程语言提供的同步原语(eg: C++ 和
     Rust 提供的 Atomic 类型)来保证多线程下的顺序一致性, 这也是无锁并发编程的基
     础.

     Rust 的多线程内存模型来源于 C++ 11, 而 C++ 11 中实现的 Atomic 类型是通过
     store 和 load 这两个 CPU 指令进行数据存取(寄存器和内存之间)的, 并且额外接受
     一个 *内存序列(Memory Order)* 作为参数. C++ 11 支持 6 种内存排序约束, 而
     Rust 是基于 LLVM 实现的, 所以 Rust 通过 LLVM 原子内存排序约束来实现不同级别
     的原子性.

**** 为什么多线程这么难
     既然有了这么多避免竞态条件和数据竞争的手段, 那么为什么提到多线程还会让广大
     开发者心生恐惧呢? 主要由以下几点原因:

     - 虽然可以使用锁来同步, 但卡覅啊中有可能忘记加锁
     - 即使没有忘记加锁, 也可能出现死锁的情况
     - 多线程程序难以调试, 如果出现了问题很难再现

     总的来说, 主要因为开发者自身很难驾驭多线程编程. 即便是技艺高超的开发者, 也
     难以保证写出没有问题的多线程代码. 难以驾驭背后的原因下雨, 开发者总是有意无
     意地将不改共享的数据错误地共享, 将其暴露在多个线程可以操作的危险区. Rust 语
     言的出现正是要解决这个问题的.
** 多线程并发编程
   Rust 为开发者提供的并发编程工具和其他语言类似, 主要包括如下两个方面:
   - *线程管理*: 在 ~std::thread~ 模块中定义了管理线程的各种函数和一些底层同步原
     语.
   - *线程同步*: 在 ~std::sync~ 模块中定义了锁、Channel、条件变量和屏障

*** 线程管理
    Rust 中的线程是本地线程, 每个线程都有自己的栈和本地状态. 
    
    ~move~ 关键字用于强制转移所有权.

    子线程的 ~join()~ 方法可以让 ~main~ 主线程等待这些子线程都执行完毕.

    如果想要多个线程协作, 通常会使用 ~join()~ 方法来指定一个线程等待其他线程执行
    完之后再执行它自己的任务.

    当 thread1 中调用 thread2 的 ~join()~ 方法时, 则 thread1 就会在调用的那一刻
    等待 thread2, 并且 *阻塞自身*, 只有 thread2 执行完毕后才继续执行 thread1 中
    的任务.

**** 定制线程
     直接使用 ~thread::spawn~ 生成的线程, 默认没有名称, 并且栈大小默认为 2MB. 如
     果想为线程指定名称或者修改默认栈大小, 则可以使用 ~thread::Builder~ 结构体来
     创建可配置的线程.

     通过 ~Builder::new()~ 方法生成的 ~Builder~ 实例, 然后分别将事先声明好的名称
     和栈大小参数传入 ~name()~ 和 ~stack_size()~ 方法中, 就可以生成指定名称和栈
     大小的线程.

     *注意*: 主线程的大小与 *Rust 语言无关*, 这是因为主线程的栈实际上就是进程的
     栈, 由操作系统来决定. 修改所生成线程的默认值也可以通过指定环境变量
     *RUST_MIN_STACK* 来完成, 但是它的值会被 ~Builder::stack_size()~ 覆盖掉.

     *注意*: ~thead::spawn~ 方法返回的是 ~JoinHandle<T>~ 类型, 而 ~Builder~ 的
     ~spawn~ 方法返回的是 ~Result<JoinHandle<T>>~ 类型, 所以这里需要加
     ~unwrap()~ 方法. ~JoinHandle<T>~ 代表线程与其他线程 ~join()~ 的权限.

**** 线程本地存储
     *线程本地存储(Thread Local Storage, TLS)* 是每个线程独有的存储空间, 在这里
     可以存放其他线程无法访问的本地数据.

     ~thread::local!~ 宏辉生成类型为 ~thread::LocalKey~ 的实例.

     当前代码实例为 FOO. 该实例是一个结构体, 提供了一个 ~with()~ 方法, 可以通过
     给该方法传入闭包来操作线程本地存储中包含的变量.

     在标准库中很多数据结构实现都使用了 ~thread_local!~ 宏来定义单个线程内的一些
     独享数据, eg: ~HashMap~.

**** 底层同步原语
     在 ~std::thread~ 模块中还提供了一些函数, 用来支持底层同步原语, 主要包括
     ~park()/unpark()~ 和 ~yield_now()~ 函数.

     ~std::thread::park()~ 函数提供了阻塞线程的基本能力, 而
     ~std::thread::thread::unpark()~ 函数可以将阻塞的线程重启. 可以利用 ~park()~
     和 ~unpark()~ 函数来方便地创建一些新的同步原语, 比如某种锁.
     *注意*: ~park()~ 函数并 *不能永久地阻塞线程*, 也可以通过
     ~std::thread::park_timeout()~ 来显式指定阻塞超时时间.

     *注意*: 千万不要使用 ~sleep()~ 来进行任何线程同步的操作, 它并不会保证线程执
     行的顺序.

     除了阻塞/重启的同步原语, ~std::thread~ 模块还提供了主动让出当前线程时间片的
     函数 ~yield_now()~. 众所周知, 操作系统是抢占式调度线程的, 每个线程都有固定
     的执行时间片, 时间片是由操作系统切分好的, 以便每个线程都可以拥有公平使用
     CPU 的机会. 但是有时开发者明确知道某个线程在一段时间内会什么都不做, 为了节
     省计算时间, 可以使用 ~yield_now()~ 函数自动放弃当前操作系统分配的时间片, 让
     给其他线程执行.
          
*** Send 和 Sync
    从 Rust 提供的线程管理工具来看, 并没有发现什么特殊的地方, 和传统语言的线程管
    理方式非常相似. 那么, Rust 是如何做到之前宣称的那样默认线程安全的呢? 这要归
    功于 ~std::marker::Sync~ 两个特殊的内置 trait. ~Send~ 和 ~Sync~ 被定义于
    ~std::marker~ 模块中, 它们属于 *标记 trait*, 其作用如下:

    - *实现了 Send 的类型, 可以安全地在线程间传递所有权*. 也就是说, 可以跨线程移
      动
    - *实现了 Sync 的类型, 可以安全地在线程间传递不可变借用*. 也就是说, 可以跨线
      程共享.

    这两个标记 trait 反映了 Rust 看待线程安全的哲学: *多线程共享内存并非线程不安
    全问题所在, 问题在于错误地共享数据*. 通过 Send 和 Sync 将类型贴上 "标签", 由
    编译器来识别这些类型是否可以在多个线程之间移动或共享, 从而做到在编译期就能发
    现线程不安全的问题. 和 Send/Sync 相反的标记是 *!Send/!Sync*, 表示不能在线程
    间安全传递的类型.

    ~std::thread::spawn~ 函数的源码实现:
    #+begin_src rust
      #[stable(feature = "rust1", since = "1.0.0")]
      pub fn spawn<F, T>(f: F) -> JoinHandle<T>
      where
          F: FnOnce() -> T,
          // 闭包 F 与 闭包的返回类型 T 都加上了 `Send` 和 `'static` 限定
          F: Send + 'static,
          T: Send + 'static,
      {
          Builder::new().spawn(f).expect("failed to spawn thread")
      }
    #+end_src

    ~Send~ 限定了闭包的类型以及闭包的返回值都必须是实现了 ~Send~ 的类型, 只有实
    现了 ~Send~ 的类型才可以在线程间传递. 而闭包的类型是和捕获变量相关的, 如果捕
    获变量的类型实现了 ~Send~, 那么闭包就实现了 ~Send~.

    而 ~'static~ 限定表示类型 ~T~ 只能是 *非引用类型(除 ~&'static~ 之外)*. 其实
    这个很容易理解, 闭包在线程间传递, 如果直接携带了引用类型, 生命周期将无法保证,
    很容易出现悬垂指针, 造成内存不安全. 这是 Rust 绝对不允许出现的情况.

    如果是不可变的变量, 可以通过 ~Arc<T>~ 来共享. ~Arc<T>~ 是 ~Rc<T>~ 的线程安全
    版本, 因为在 ~Rc<T>~ 内部并非使用原子操作, 所以在多个线程之间共享会出现安全
    问题; 而在 ~Arc<T>~ 内部使用了原子操作, 所以默认线程安全.

    源码中为 ~Arc<T>~ 实现 ~Send~ 和 ~Sync~
    #+begin_src rust
      #[stable(feature = "rust1", since = "1.0.0")]
      unsafe impl<T: ?Sized + Sync + Send> Send for Arc<T> {}
      #[stable(feature = "rust1", since = "1.0.0")]
      unsafe impl<T: ?Sized + Sync + Send> Sync for Arc<T> {}
    #+end_src

    可以看出, 只要 T 是实现了 ~Send~ 和 ~Sync~ 的类型, 那么 ~Arc<T>~ 也会实现
    ~Send~ 和 ~Sync~. 值得注意的是, ~Send~ 和 ~Sync~ 这两个 trait 是 unsafe 的,
    这意味着如果开发者为自定义类型手动实现这两个 trait, 编译器是 *不保证线程安全
    的*. 实际上, 在 Rust 标准库 ~std::marker~ 模块内部, 就为所有类型默认实现了
    ~Send~ 和 ~Sync~, 就是为 *所有类型设定好了默认的线程安全规则*.

    #+begin_src rust
      unsafe impl Send for .. {}
      impl<T: ?Sized> !Send for *const T { }
      impl<T: ?Sized> !Send for *mut T { }
      unsafe impl Sync for .. { }
      impl<T: ?Sized> !Sync for *const T { }
      impl<T: ?Sized> !Sync for *mut T { }
      mod impls {
          unsafe impl<'a, T: Sync + ?Sized> Send for &'a T { }
          unsafe impl<'a, T: Send + ?Sized> Send for &'a mut T { }
      }
    #+end_src
    

    第 1 行和第 4 行使用了一种特殊的语法, 分别表示为所有类型实现了 ~Send~ 和
    ~Sync~. 这里要注意 ~Send~ 和 ~Sync~ 本身只是标记 trait, 没有乐乐虎没咯嗯的方
    法. 如果想使用第 1 行和第 4 行这样的语法, *必须满足 2 个条件*:
    - impl 和 trait 必须在同一个模块中
    - 在该 trait 内部不能有任何方法

    第 2 行和第 3 行以及第 5 行和第 6 行分别为 ~*const T~ 和 ~*mut T~ 类型实现了
    ~!Send~ 和 ~!Sync~, 表示实现这两种 trait 的类型不能在线程间安全传递.

    第 7 ~ 10 行, 分别为 ~&'a T~ 和 ~&' a mut T~ 实现了 ~Send~, 但是对 ~T~ 的限
    定不同. ~&'a T~ 要求 ~T~ 必须是实现了 ~Sync~ 的类型, 表示 *只要实现了 Sync
    的类型, 其不可变借用就可以安全地在线程间共享*; 而 ~&'a mut T~ 要求 ~T~ 必须
    是实现了 ~Send~ 的类型, 表示 *只要实现了 ~Send~ 的类型, 其可变借用就可以安全
    地在线程间移动*.

    除在 ~std::marker~ 模块中标记的上述未实现的 ~Send~ 和 ~Sync~ 的类型之外, 在
    其他模块中也有. eg: 在 ~Cell~ 和 ~RefCell~ 都实现了 ~!Sync~, 表示无法跨线程
    共享; eg2: ~Rc~ 实现了 ~!Send~, 表示无法跨线程移动.

    通过 ~Send~ 和 ~Sync~ 构建的规则, 编译器就可以方便地识别线程安全问题.

    ~Arc<T>~ 默认是不可变的, 当想要使用具备内部可变性的类型时, 可以使用 ~Cell~,
    ~RefCell~.

    ~RefCell<String>~ 没有实现 ~Sync~, 但是 ~Arc~ 只支持实现 ~Sync~ 的类型. 同时,
    错误信息也会提示 ~RefCell<String>~ 不能在线程间安全共享.

*** 使用锁进行线程同步
    要修复 11-20 中的错误, 只需要使用支持跨线程安全共享可变变量的容器即可, 所以
    可以使用 Rust 提供的 ~Mutex<T>~ 类型.

**** 互斥锁(Mutex)
     ~Mutex<T>~ 其实就是 Rust 实现的互斥锁, 用于保护共享数据. 如果类型 ~T~ 实现
     了 ~Send~, 那么 ~Mutex<T>~ 会自动实现 ~Send~ 和 ~Sync~. 在互斥锁的保护下,
     每次只能有一个线程有权限访问数据, 但在访问数据之前, 必须通过调用 ~lock()~
     方法阻塞当前线程, 直到得到互斥锁, 才能获得访问权限.

     ~Mutex<T>~ 类型实现的 ~lock()~ 方法会返回一个 ~LockResult<MutexGuard<T>>~
     类型, ~LockResult<T>~ 是 ~std::sync~ 模块中定义的错误类型, ~MutexGuard<T>~
     基于 *RAII* 机制实现, 只要超出作用域范围就会自动释放锁. 另外, ~Mutex<T>~ 也
     实现了 ~try_lock()~ 方法, 该方法再获取锁的时候不会阻塞当前线程, 如果得到锁,
     就返回 ~MutexGuard<T>~, 反之返回 ~Err~.

**** 跨线程恐慌和错误处理
     当子线程发生恐慌时, 不会影响到其他线程, 恐慌不会在线程间传播. 当子线程发生
     错误时, 因为 Rust 基于返回值的错误处理机制, 也让跨线程错误处理变得非常方便.
     ~std::thread::JoinHandle~ 实现的 ~join()~ 方法会返回 ~Result<T>~, 当子线程
     内部发生恐慌时, 该方法会返回 ~Err~, 但是通常不会对此类 ~Err~ 进行处理, 而是
     直接使用 ~unwrap()~ 方法, 如果获取到合法的结果, 则正常使用; 若是 ~Err~, 则
     故意让父线程也发生恐慌, 这样就可以把子线程的恐慌传播到父线程, 及早发现问题.

     但是如果线程在获得锁之后发生恐慌, 则称这种情况为 "*中毒(Posion)*".

     使用 ~is_poisoned()~ 方法来查看获得互斥锁的子线程是否发生了恐慌.
     发生恐慌后, ~mutex.lock()~ 的 ~Err~ 会返回 ~PoisonError<T>~ 类型, 提供
     ~get_ref()~ 和 ~get_mut()~ 方法可以得到其内部包装的 ~T~ 类型.

**** 死锁
     当主线程一直持有互斥体的锁时, 将会导致所有的子线程阻塞. 同时, ~main~ 主线程
     还在等待子线程完成任务, 造成了死锁.

**** 读写锁(RwLock)
     在 ~std::sync~ 模块中还提供了另外这一种锁: *读写锁(~RwLock<T>~)*. 与
     ~Mutex<T>~ 十分类似, 不同点在于, ~RwLock<T>~ 对线程进行 *读者(Reader)* 和
     *写者(Writer)* 的区分, 不像 ~Mutex<T>~ 只能独占访问. 该锁支持多个读线程和一
     个写线程, 其中读线程只允许进行只读访问, 而写线程只能进行独占写操作. 只要线
     程没有拿到写锁, ~RwLock<T>~ 就允许任意数量的读线程获得读锁. 和 ~Mutex<T>~
     一样, ~RwLock<T>~ 也会因为恐慌而 "中毒".

     
     使用 ~read()~ 方法来获取读锁, 使用 ~write()~ 方法来获取写锁. *读锁和写锁妖
     使用显式作用域块隔离开*, 这样的话, 读锁或写锁才能在离开作用域之后自动释放;
     否则会引起死锁, 因为 *读锁和写锁不能同时存在*.
*** 屏障和条件变量
    Rust 除支持互斥锁和读写锁之外, 还支持 *屏障(Barrier)* 和 *条件变量(Condition
    Variable)*.

    屏障的用法和互斥锁类似, 它可以通过 ~wait()~ 方法再某个点阻塞全部进入临界区的
    线程.

    屏障的 ~wait()~ 方法会阻塞当前线程, 一般用于实现线程同步.

    *条件变量* 跟屏障有些类似, 但它不会阻塞全部线程, 而是满足指定条件之前阻塞某
    一个得到互斥锁的线程.

    *注意*: *在运行中每个条件变量每次只能和一个互斥体一起使用*. 在有些线程需要获
    取某个状态陈力的情况下, 如果单独使用互斥锁会比较浪费系统组员, 因为只有多次出
    入临界区才能获取到某个状态的信息. 此时就可以配合使用条件变量, 当状态成立时通
    知互斥体就可以, 因此减少了系统资源的浪费.
*** 原子类型
    互斥锁, 读写锁等同步原语确实可以满足基本的线程安全需求, 但是有时候使用锁会影
    响相连, 甚至存在死锁的风险, 因此引入了原子类型.

    原子类型内部封装了编程语言和操作系统的 "契约", 基于此契约来实现一些自带原子
    操作的类型, 而不需要对其使用锁来保证原子性, 从而实现无锁(Lock-Free)并发编程.
    这个契约就是 *多线程内存模型*. Rust 的多线程内存模型借鉴于 C++ 11, 它保证了
    多线程并发的顺序一致性, 不会因为底层的各种优化重排行为而失去原子性.

    对于开发者来说, 如果说编程语言提供的锁机制属于 "白盒" 操作的话, 那么原子类型
    就属于 "黑盒" 操作. 有如下操作:
    - *Load*: 表示从一个原子类型内部读取值
    - *Store*: 表示往一个原子类型内部写入值

    各种提供原子 "读取-修改-写入" 的操作:
    - *CAS(Compare-And-Swap)*: 表示比较并交换
    - *Swap*: 表示原子交换操作
    - *Compare-Exchange*: 表示比较/交换操作
    - *Fetch-**: 表示 fetch_add、fetch_sub、fetch_and 和 fetch_or 等一系列原子的加
      减或逻辑运算
    - 其他

    通过上面原子类型 "对外公开" 的一系列原子操作, 就可以从外部来控制多线程内存模
    型内部的顺序一致性, 从而不用担心底层各种指令重排会导致线程不安全的问题.

**** Rust 标准库中提供的原子类型
     在 Rust 标准库 ~std::sync::atomic~ 模块中暂时提供了 4 个稳定的原子类型, 分
     别是 ~AtomicBool~, ~Atomiclsize~, ~AtomicPtr~ 和 ~AtomicUsize~, 另外还有很
     多基本的原子类型会逐步稳定. 这些原子类型均提供了一系列原子操作.

     原子类型虽然可以保证原子性, 但它自身不提供在多线程中共享的方法, 所以需要使
     用 ~Arc<T>~ 将其跨线程共享.

     "自旋" 就是指在 *语义上表示这种不断循环获取锁状态的行为*.
`
**** 内存顺序
     原子类型除基本的原子操作之外, 还提供了内存顺序参数. 虽然每个原子类型对开发
     者而言是一个 "黑盒", 但也可以通过提供内存顺序参数来控制底层线程执行顺序的参
     数. 控制内存顺序实际上就是控制底层线程同步, 以便消除底层因为编译器优化或指
     令重排而引发的竞态条件.

     在 ~std::sync::atomic::Ordering~ 模块中定义了 Rust 支持的 5 种内存顺序.
     #+begin_src rust
       #[stable(feature = "rust1", since = "1.0.0")]
       #[derive(Copy, Clone, Debug, Eq, PartialEq, Hash)]
       #[non_exhaustive]
       pub enum Ordering {
           #[stable(feature = "rust1", since = "1.0.0")]
           Relaxed,
           #[stable(feature = "rust1", since = "1.0.0")]
           Release,
           #[stable(feature = "rust1", since = "1.0.0")]
           Acquire,
           #[stable(feature = "rust1", since = "1.0.0")]
           AcqRel,
           #[stable(feature = "rust1", since = "1.0.0")]
           SeqCst,
       }
     #+end_src

     - *排序一致性顺序*: ~Ordering::SeqCst~
     - *自由顺序*: ~Ordering::Relaxed~
     - *获取 - 释放顺序*: ~Ordering::Release~, ~Ordering::Acquire~ 和
       ~Ordering::AcqRel~.

     Rust 支持的 5 种内存顺序与其底层的 LLVM 支持的内存顺序是一致的.

     *排序一致性顺序*: 是最直观、最简单的内存顺序, 它规定使用排序一致性顺序, 也就
     是指定 ~Ordering::SeqCst~ 的原子操作, 都必须先存储(store)再加载(load). 这就
     意味着: 多线程环境下, 所有的原子写操作都必须在读操作之前完成. 通过这种规定,
     就强行指定了底层多线程的执行顺序, 从而保证了多线程中所有操作的全局一致性.
     但是简单是要付出代价的, 这种方式需要对 *所有的线程进行全局同步*, 这就存在性
     能损耗.

     *自由顺序*: 正好是排序一致性顺序的对立面, 顾名思义, 它完全不会对线程的顺序
     进行干涉. 也就是说, 线程只进行原子操作, 但线程之间会存在竞态条件. 使用这种
     内存顺序是比较危险的, 只有在明确了解当前使用场景且必须使用它的情况下(eg: 只
     有读操作), 才可使用自由顺序.

     *获取 - 释放顺序*: 是除排序一致性之外的优先选择. 这种内存顺序并不会对全部的
     线程进行统一强制性的执行顺序要求. 在该内存顺序中, ~store~ 代表释放(Release)
     语义, 而 ~load~ 代表获取(Acquire)语义, 通过这两种操作的协作实现线程同步. 其
     中, ~Ordering::Release~ 表示使用该顺序的 ~store~ 操作, 之前所有的操作对于使
     用 ~Ordering::Acquire~ 顺序的 ~load~ 操作都是可见的; 反之亦然, 使用
     ~Ordering::Acquire~ 顺序的 ~load~ 操作对于使用 ~Ordering::Release~ 的
     ~store~ 操作都是可见的; ~Ordering::AcqRel~ 代表读时使用 ~Ordering::Acquire~
     顺序的 ~load~ 操作, 写时使用 ~Ordering::Release~ 顺序的 ~store~ 操作.

     获取 - 释放顺序虽然不像排序一致性顺序那样对全局线程统一排序, 但是它让每个线
     程都能按固定的顺序执行. 

     在日常开发的选择和底层硬件环境也有关系. 一般情况下建议使用
     ~Ordering::SeqCst~. 在需要性能优化的情况下, 先调研并发程序运行的硬件环境,
     再优先选择获取 - 释放顺序(~Ordering::Release~, ~Ordering::Acquire~ 和
     ~Ordering::AcqRel~ 按需选择). 除非必要, 否则不要使用 ~Ordering::Relaxed~.

*** 使用 Channel 进行线程间通信
    坊间流传着一局非常经典的话: *不要通过共享内存来通信, 而应该使用通信来共享内
    存*. 这句话中蕴含着一种古老的编程哲学, 那就是消息传递, 通过消息传递的手段可
    以降低由共享内存而产生的耦合.

    基于消息通信的并发模型主要有 2 种: *Actor* 模型和 *CSP* 模型. Actor 模型的
    代表语言是 Erlang, 而 CSP 模型的代表语言是 Golang. 这两种并发模型的区别如
    下:

    - 在 Actor 模型中, 主角是 Actor, Actor 之间直接发送、接收消息
    - 在 Actor 模型中, Actor 之间是直接通信的; 而在 CSP 模型中, 依靠 Channel 来
      通信
    - Actor 模型的耦合程序要高于 CSP 模型, 因为 CSP 模型不关注消息发送者和接受
      者.

    这两种模型都存在了很多年, 随着 Golang 语言的出现, CSP 模型再次回到开发者的
    视线中. Rust 标准库也选择实现了 CSP 并发模型.  

**** CSP 并发模型
     CSP(Communicating Sequential Processes, 通信顺序进程)是一个精确描述并发的
     数学理论, 基于该理论构建的并发程序不会出现常见的问题, 并且可以得到数学证明.
     CSP 对程序中每个阶段所包含对象的行为进行精确的指定和验证, 它对并发程序的设
     计影响深远.

     *CSP 模型* 的基本构造是 *CSP 进程* 和 *通信通道*. 注意: 此处 CSP 进程是并
     发模型中的概念, 不是操作系统中的进程. 在 CSP 中每个事件都是进程, 进程之间
     没有直接交互, 只能通过通信通道来交互. CSP 进程通常是匿名的, 通信通道传递消
     息通常使用同步方式.

     CSP 理论在很多语言中得以实现, 包括 Java、Golang 和 Rust 等. 在 Rust 的实现
     中, 线程就是 CSP 进程, 而通信通道就是 Channel. 在 Rust 标准库的
     ~std::sync::mpsc~ 模块中为线程提供了 Channel 机制, 其具体实现实际上是一个
     *多生产者单消费者(Multi-Producer-Single-Consumer, MPSC)* 的 先进先出(FIFO)
     队列. 线程通过 Channel 进行通信, 从而可以实现无锁并发.

**** 生产者消费者模式与 Channel
     生产者消费者模式是指通过一个中间层来解决数据生产者和消费者之间的耦合问题.
     生产者和消费者之间不直接通信, 而是分别与中间层进行通信. 生产者向中间层生产
     数据, 消费者从中间层获取数据进行消费, 这样就巧妙地平衡了生产者和消费者对数
     据的处理能力.

     一般情况下, 使用一个 FIFO 队列来充当中间层. 在多线程环境下, 生产者就是生产
     数据的线程, 消费者就是消费数据的线程. Rust 实现的是多生产者单消费者模式.

     该 FIFO 队列就是 CSP 模型中的 Channel 的具体实现, 在标准库
     ~std::sync::mpsc~ 模块中定义了以下三种类型的 CSP 进程:

     - *Sender*: 用于发送异步消息
     - *SyncSender*: 用于发送同步消息
     - *Receiver*: 用于接收消息

     Rust 中的 Channel 包括两种类型:
     - *异步无界 Channel*, 对应于 channel 函数, 会返回 *(Sender, Receiver)* 元
       组. 该 Channel 发送消息是异步的, 并且不会阻塞. *无界*, 是指理论上缓冲区
       是无限的.
     - *同步有界 Channel*, 对应于 sync_channel 函数, 会返回 *(SyncSender,
       Receiver)* 元组. 该 Channel 可以预分配具有固定大小的缓冲区, 并且发送消息
       是同步的, 当缓冲区满时会阻塞消息发送, 知道有可用的缓冲空间. 当该 Channel
       缓冲区大小为 0 时, 就会变成一个 "点", 在这种情况下, Sender 和 Receiver
       之间的消息传递是原子操作.

     Channel 之间的发送或接受操作都会返回一个 Result 类型用于错误处理. 当
     Channel 发生意外时会返回 Err, 所以通常使用 ~unwrap()~ 在线程间传播错误, 及
     早发现问题.

     只有两个线程通信的 Channel, 叫做 *流通道(Streaming Channel)*. 在流通道内部,
     实际上 Rust 会默认使用 *单生产者单消费者队列(SPSC)* 来提升性能.

     多生产者单消费者的 Channel, 叫做 *共享通道(Sharing Channel)*.
        
**** Channel 死锁
     并不是没有锁就不会发生死锁的行为.

     当使用 *共享通道时*, ~tx~ 不 ~drop()~, 主线程 ~rx.iter()~ 会一直等待.

     当使用 *流通道时*, 发送端 ~tx~ 在离开作用域之后会自动调用析构函数
     ~drop()~, 在 ~drop()~ 中会调用 ~tx~ 内部的 ~drop_channel()~ 方法来 *断开*
     (DISCONNECT) Channel. 

     当 Channel 是共享通道时, 在 for 循环中调用 ~tx~ 的 ~clone()~ 方法; 当
     Channel 是流通道时, ~tx~ 在离开子线程作用域之后通过析构函数就可以断开
     Channel. 

     之所以存在这样的区别, 在于共享通道的流底层的构造有所不同. 流通道底层自动使
     用 SPSC 队列来优化性能, 因为流通道只是用于两个线程之间的通信. 但是共享通道
     底层使用的还是 MPSC 队列, 在析构行为上比流通道略为复杂. 所以在通常的开发过
     程中, 要注意这两类 Channel 的区别.

     在底层不管是 SPSC 还是 MPSC 队列, 甚至是同步 Channel 使用的内置独立的队列,
     都是 *基于链表实现的*. 使用链表的好处就是可以提升性能. 在生产数据时, 只需
     要在链表头部添加新的元素即可; 在消费数据时, 只需要从链表尾部取元素即可.

**** 利用 Channel 模拟工作量证明
     接下来, 我们使用 Channel 来解决一个来自数据货币领域的问题. 众所周知, 比特
     币开创了数字货币时代, 它不仅仅革新了金融领域, 更重要的是它带来了区块链的概
     念. 区块链采用密码学的方法来保证已有的数据不可篡改, 采用共识算法为新增的数
     据达成共识, 这完全是与生俱来的且去中心化的 "公信力". 而信任是人类社会一切
     交易的前提, 于是, 这种借助于密码学和算法取得信任的区块链技术, 正逐渐成为当
     前互联网上各种商业信用体的基础设施.

     在比特币中, 最流行的一个词就是 "挖矿", 就是指 *工作量证明(Proof of Work,
     PoW)*.

     该术语最早被用于防范拒绝服务攻击等领域. 下面简单用一个示例来说明 *工作量证
     明机制的基本原理*.

     - 给定一个字符串或数字, eg: 42
     - 给定一个工作目标: 找到另外一个数字, 要求该数字和 42 相乘后的结果, 经过
       Hash 函数处理后, 满足得到的加密字串以 "00000" 开头. 可以通过对 "00000"
       增加或减少 0 的个数来控制查找的难度.
     - 为了找到这个数字, 需要从数字 1 开始递增查找, 查找到满足条件的数字.

     要找到这个数字, 就需要大量的计算. 在这个示例中, 数字期望的计算次数就是 "工
     作量", 重复多次验证是否满足条件就是 "工作量证明", 这是一个符合统计学规律的
     概率事件. 当然, 比特币和以太坊中真实的工作量证明算法比这个示例更复杂一些,
     但原理是相似的.

     现在, 使用 Rust 来实现上述示例描述哦模拟工作量证明过程. *代码结构设计如下*:
     - 使用多线程来加速查找过程
     - 将查找到打的符合条件的数字和加密字串通过 Channel 传递到另外一个线程中并
       输出.

     为简单器件, 将整个代码都写到同一个文件中. 接下来, 使用 ~cargo new --bin
     pow~ 创建一个新项目. 实现此过程中, 需要用到两个第三方包 -- 用来求 Hash 值
     的 rust-crypto 和用来方便迭代的 itertools.
        
     整个实现过程中需要注意一下几个地方:
     - 如何正确地分离生产线程和消费线程?
     - 如何正确地划分并发任务?
     - 如何正确地识别临界区, 以及如何正确地使用原子类型及其内存顺序?

*** 内部可变性探究
    在 Rust 提供的并发编程工具中, 基本都支持内部可变性, 在行为上与 ~Cell<T>~,
    ~RefCell<T>~ 比较相似.
    
    ~Mutex~ 源码实现
    #+begin_src rust
      #[stable(feature = "rust1", since = "1.0.0")]
      #[cfg_attr(not(test), rustc_diagnostic_item = "mutex_type")]
      pub struct Mutex<T: ?Sized> {
          // 包装了用于调用底层操作系统 API 的 `sys::MovableMutex`
          inner: sys::MovableMutex,
          // 用于标记该锁是否已 "中毒"
          poison: poison::Flag,
          // 锁包含的数据
          data: UnsafeCell<T>,
      }
    #+end_src

    由上可知, 内部可变性是由 ~UnsafeCell<T>~ 提供的.

    继续查看其他源码实现:
    ~Cell<T>~, ~RefCel<T>~, ~RwLock<T>~ 等源码实现:
    #+begin_src rust
      #[stable(feature = "rust1", since = "1.0.0")]
      #[repr(transparent)]
      pub struct Cell<T: ?Sized> {
          value: UnsafeCell<T>,
      }
      #[stable(feature = "rust1", since = "1.0.0")]
      pub struct RefCell<T: ?Sized> {
          borrow: Cell<BorrowFlag>,
          value: UnsafeCell<T>,
      }
      #[stable(feature = "rust1", since = "1.0.0")]
      pub struct RwLock<T: ?Sized> {
          inner: Box<sys::RWLock>,
          poison: poison::Flag,
          data: UnsafeCell<T>,
      }
      #[cfg(target_has_atomic_load_store = "8")]
      #[stable(feature = "rust1", since = "1.0.0")]
      #[repr(C, align(1))]
      pub struct AtomicBool {
          v: UnsafeCell<u8>,
      }
      #[stable(feature = "rust1", since = "1.0.0")]
      pub struct Sender<T> {
          inner: UnsafeCell<Flavor<T>>,
      }
      #[stable(feature = "rust1", since = "1.0.0")]
      pub struct Receiver<T> {
          inner: UnsafeCell<Flavor<T>>,
      }
    #+end_src

    由上可知, 这些拥有内部可变性的结构体都是基于 ~UnsafeCell<T>~ 实现的.

    继续查看 ~UnsafeCell<T>~ 的源码实现:
    #+begin_src rust
      #[lang = "unsafe_cell"]
      #[stable(feature = "rust1", since = "1.0.0")]
      #[repr(transparent)]
      #[repr(no_niche)] // rust-lang/rust#68303.
      pub struct UnsafeCell<T: ?Sized> {
          value: T,
      }
      #[stable(feature = "rust1", since = "1.0.0")]
      // 实现了 `!Sync`, 所以单独使用该类型并不能保证线程安全
      impl<T: ?Sized> !Sync for UnsafeCell<T> {}
      impl<T: ?Sized> UnsafeCell<T> {
          #[inline]
          #[stable(feature = "rust1", since = "1.0.0")]
          #[rustc_const_stable(feature = "const_unsafecell_get", since = "1.32.0")]
          // 将不可变借用转为可变的原生指针
          pub const fn get(&self) -> *mut T {
              // 先转为 *const T, 再转为 *mut T
              self as *const UnsafeCell<T> as *const T as *mut T
          }
          #[inline]
          #[unstable(feature = "unsafe_cell_get_mut", issue = "76943")]
          pub fn get_mut(&mut self) -> &mut T {
              unsafe { &mut *self.get() }
          }
      }
    #+end_src

    ~UnsafeCell<T>~ 只是一个泛型结构体, 它属于 *语言项(Lang Item)*, 所以编译器会
    对它进行某种特殊的照顾.

    关于 ~get()~ 方法: 
    一般来说, 在 Rust 中将不可变借用转换为可变借用属于 *未定义行为*, 编译器不允
    许开发者随意对这两种引用进行相互转换. 但是, ~UnsafeCell<T>~ 是唯一的例外. 这
    也是 ~UnsafeCell<T>~ 属于语言项的原因, 它属于 Rust 中将不可变转换为可变的唯
    一合法渠道, 对于使用了 ~UnsafeCell<T>~ 的类型, 编译器会关闭相关的检查.

    因此, 在上述各种拥有内部可变性的容器内部均使用了 ~UnsafeCell<T>~, 不会违反
    Rust 的编译器安全检查.
    
*** 线程池
    在实际应用中, 多线程并发更常用的方式是使用线程池. 线程虽然比进程轻量, 但如果
    每次处理任务都要重新创建线程的话, 就会导致线程过多, 从而带来更多的创建和调度
    的开销. 采用线程池的方式, 不仅可以实现对线程的复用, 避免多次创建、销毁线程的
    开销, 而且还能保证内核可以被充分利用.

    实现一个线程池需要考虑以下几点:
    - 工作线程: 用于处理具体任务的线程
    - 线程池初始化: 即通过设置参数指定线程池的初始栈大小、名称、工作线程数等
    - 待处理任务的存储队列: 工作线程数是有限的, 对于来不及处理的任务, 需要暂时保
      存到一个队列中.
    - 线程池管理: 即管理线程池中的任务数和工作线程的状态. eg: 在没有空闲工作线程
      时则需要等待, 或者在需要时主线程等待所有任务执行完毕.

    接下来参考第三方包 *[[https://crates.io/crates/threadpool][threadpool]]* 的实现, 来说明如何使用 Rust 标准库中提供的并
    发工具来实现一个简单的线程池.

    - 线程池: 通过创建一个线程池结构体来控制线程池的初始化. 为此结构体实现
      Builder 模式, 定制初始化参数, 并且实现工作线程的方法.
    - 待处理任务队列: 使用无界队列 ~mpsc::channel~, 缓存待处理的任务
    - 线程池管理: 使用原子类型对工作任务状态进行计数, 达到管理的目的.

    使用 ~cargo new --bin thread_pool~ 创建一个新项目, 添加 ~nums_cpus~ 的依赖
    ~num_cpus~ 依赖可以识别当前运行的计算机中 CPU 的个数, 将其作为线程池默认的工
    作线程数.

*** 使用 Rayon 执行并行任务
    *Rayon* 是一个第三方包, 使用它可以轻松地将顺序计算转换为安全的并行计算, 并且
    保证无数据竞争. Rayon 提供了 2 种使用方法:

    - *并行迭代器*: 即可以并行执行的迭代器
    - *. ~join()~ 方法*: 可以并行处理递归或分治风格的问题

    使用 ~join()~ 方法 *不一定包保证并行执行闭包*, Rayon 底层使用线程池来执行任
    务, 如果工作线程被占用, Rayon 会选择顺序执行. Rayon 的并行能力基于一种叫做
    *工作窃取(Work-Stealing)* 的技术, 线程池分钟的每个线程都有一个互不影响的任务
    队列(双端队列), 线程每次都从当前任务队列的头部取出一个任务来执行. 如果某个线
    程对应的队列已空并且处于空闲状态, 而其他线程的队列中还有任务需要处理, 但是该
    线程处于工作状态, 那么空闲的线程就可以从其他线程的队列尾部取一个任务来执行.
    这种行为表现就像空间的线程去偷工作中的线程任务一样, 所以叫做 "工作窃取".

    Rayzon 的更多细节, 参考 [[https://github.com/rayon-rs/rayon/tree/master/rayon-demo][rayon-demo]]

*** 使用 Crossbeam
    Crossbeam 是比较常用的第三方类库, 在实际开发中通常用它来代替标准库. 它是对标
    准库的扩展和包装, 一共包含 4 大模块.

    - 用于增强 ~std::sync~ 的原子类型. 提供了 C++ 11 风格的 Consume 内存顺序原子
      类型 AtomicConsume 和用于存储和检索的 Arc 的 ArcCell.
    - 对于标准库 thread 和各种同步原语的扩展, 提供了很多使用的工具. eg: Scoped
      线程、支持缓存行填充的 CachePadded 等
    - 提供了 MPMC 的 Channel, 以及各种无锁并发数据结构. 包括: 并发工作窃取双端队
      列、并发无锁队列(MS-Queue)和无锁栈(Treiber Stack)
    - 提供了并发数据结构中需要的内存管理组件 crossbeam-epoch. 因为在多线程并发情
      况下, 如果线程从并发数据结构中删除某个节点, 但是该节点还有可能被其他线程使
      用, 则无法立即销毁该节点. Epoch GC 允许推迟销毁, 直到它变的安全. 在不久的
      将来, 其还将支持险象指针(Hazard Pointer, HP) 和 QSBR(Quiescent-State-Based
      Reclamation) 回收算法.

**** 扩展原子类型
     Crossbeam 的 crossbeam-utils 子包中提供了 AtomicConsume trait, 是对标准库中
     原子类型内存顺序的增强. 该 trait 允许院子类型以 "Consume" 内存顺序进行读取.
     "Consume" 内存顺序是 C++ 中支持的一种内存顺序, 可以称为 *消耗-释放顺序*. 相
     对于获取-释放顺序而言, 消耗-释放顺序的性能更好. 因为获取-释放顺序会同步所有
     写操作之前的读操作, 而消耗-释放顺序则只会同步数据之间有相互依赖的操作, 粒度
     更细, 所以性能更好. 目前仅 ARM 和 AArch64 架构支持, 在其他架构上还是要回归
     到获取-释放顺序.

     通过 crossbeam-utils 包, 已经为标准库 ~std::sync::atomic~ 中的 AtomicBool、
     AtomicUsize 等原子类型实现了该 trait, 只需要调用 ~load_consume()~ 方法就可
     以使用该内存顺序.

     在最新的 crossbeam-utils 包中, 还增加了一个原子类型 AtomicCell, 其等价于一
     个具有原子操作的 ~Cell<T>~ 类型.

**** 使用 Scoped 线程
     在标准库生成的子线程中, 无法安全地使用父线程中的引用

     实际上, 闭包中的 scope 参数是一个由内部使用的 Scope 结构体, 该结构体会负责
     子线程的创建, ~join()~ 父线程和析构等工作, 以保证引用的安全.

**** 使用缓存行填充提升并发性能
     在并发编程中, 有一个号称 "无声性能杀手" 的概念叫做 *伪共享(False Sharing)*.
     为了提升性能, 现代 CPU 都有自己的多级缓存. 而在缓存系统中, 都是以缓存行
     (Cache Line) 为基本单位进行存储的, 其长度通常是 64 字节. 当程序中的数据存储
     在彼此相邻的连续内存中时, 可以被 L1 级缓存一次加载完成, 享受缓存带来的性能
     极致. 当数据结构中的数据存储在非连续内存中时, 则会出现缓存未命中的情况.

     将数据存储在连续紧凑的内存中虽然克制带来高性能, 但是将其置于多线程下就会发
     生问题. 多线程操作同一个缓存行的不同字节, 将会产生竞争, 导致线程彼此牵连,
     相互影响, 最终变成串行的程序, 降低了并发性, 这就是所谓的伪共享. 因此, 为了
     避免伪共享, 就需要将多线程之间的数据进行隔离, 使得它们不在同一个缓存行, 从
     而提升多线程的并发性能.

     避免伪共享的方案有很多, 其中一种方案就是刻意增大元素间的间隔, 使得不同线程
     的存取单元位于不同的缓存行. Crossbeam 提供了 ~CachePadded<T>~ 类型, 可以进
     行 *缓存行填充(Padding)*, 从而避免伪共享.

     在 Crossbeam 提供的并发数据结构中就用到了缓存行填充. eg: 并发的工作窃取双端
     队列 crossbeam-deque, 就用到了缓存行填充来避免伪共享, 提升并发性能.
     
**** 使用 MPMC Channel
     Crossbeam 还提供了一个 ~std::sync::mpsc~ 的替代品 MPMC Channel, 也就是多生
     产者单消费者通道. 标准库 mpsc 中的 Sender 和 Receiver 都没有实现 Sync, 但是
     Crossbeam 提供的 MPMC Channel 的 Sender 和 Receiver 都实现了 Sync.

     所以, 可以通过引用来共享 Sender 和 Receiver.

     使用 ~channel::unbounded()~ 函数来创建 *无界通道*. Crossbeam 提供的 MPMC
     Channel 和标准库的 Channel 类似, 也提供了 *无界通道* 和 *有界通道* 两种类型.

     接下来, 使用 scope 函数创建了两个 Scoped 子线程, 并通过获取通道发送端 s 和
     接收端 r 的引用来共享使用 Channel. 当然, 也可以通过 ~clone()~ 方法来共享通
     道两端.

     在 Crossbeam 中还提供了 ~select!~ 宏, 用于方便地处理一组通道中的消息.

     ~select!~ 宏每次只会执行 *一个操作*. 对于 ~select!~ 宏来说, 如果同时有多个
     操作已经准备就绪, 则会随机选择一个自信; 否则, 只选择最先准备就绪的那个操作
     来执行.

     在标准库 ~std::sync::mpsc~ 模块中也提供了 Select 类型, 但目前还是实验特性.
** 异步并发
   本章开头的 "通用概念" 中已经介绍了异步并发相关背景, 了解到异步编程的发展一共
   经历了三个阶段:
   1. 直接使用回调函数, 随之带来的问题是 "回调地狱"
   2. 使用 Promise/Future 并发模型, 解决了回调函数的问题, 但是代码依旧有很多冗余
   3. 利用协程实现 async/await 解决方案, 也号称 "异步的终极解决方案"

   目前, 很多编程语言都支持异步并发, 但并非都支持到第三个阶段. 

   各种语言对异步编程的支持参差不齐, 但异步解决方案 async/await 几乎已经成为业界
   的事实标准.

   在经过一系列版本迭代之后, Rust 才确定了新的发展路线:
   即: 成为能开发高性能网络服务的首选语言. 因此, Rust 引入了生成器, 随之又先后引
   入了 Future 并发模型和 async/await 方案. 然而, 引入异步并发模型的过程并非一帆
   风顺, 本来计划在 Rust 2018 稳定版中包含 async/await 语法, 但最后不得不延期.

*** 生成器
    如果要支持 *async/await* 异步开发, 最好是能有协程的支持. 所以, Rust 的第一步
    是需要引进 *协程(Corotine)*.

    协程的实现一般分为两种, 一种是 *有栈协程(Stackful)*; 另一种是 *无栈协程
    (Stackless)*. 对于有栈协程的实现, 一般每个协程都自带独立的栈, 功能强大, 但是
    比较耗内存, 性能不如无栈协程. 而无栈协程一般是基于 *状态机(State Machine)*
    来实现的, 不使用独立的栈, 具体的应用形式 *生成器(Generator)*, 常见的有 ES6
    和 Python 语言中支持的生成器. 这种形式的协程性能更好, 而功能要弱于有栈协程,
    但也够用了. 在 Rust 标准库中支持的协程功能, 就属于无栈协程.

**** 什么是生成器
     创建的 Generator 形式上看像闭包, 但它不是闭包, 而是 *生成器*. 其中的
     *yield* 是专门为生成器引入的关键字. 需要注意: 生成器不能像闭包那样接受参数.

     生成器使用 yield 来设置状态, 然后通过调用 ~resume()~ 方法来达到状态的流转.
     整个生成器实际上就是一个状态机.

     返回的结果实际上是一种枚举类型 ~GeneratorState<Y, R>~, 该类型只包括
     ~Yielded(Y)~ 和 ~Complete(R)~ 两种值. 其中 ~Yield(Y)~ 表示在生成器执行过程
     中产生的各种状态, 也就是程序在生成器代码中挂起的位置; 而 ~Complete(R)~ 表示
     生成器执行完成后最终返回的值.

**** 生成器的实现原理
     在 Rust 中 Generator 被定义为一个 trait:
     #+begin_src rust
       #[lang = "generator"]
       #[unstable(feature = "generator_trait", issue = "43122")]
       #[fundamental]
       pub trait Generator<R = ()> {
           // yield 状态类型
           type Yield;
           // 最终返回类型
           type Return;

           fn resume(self: Pin<&mut Self>, arg: R) -> GeneratorState<Self::Yield, Self::Return>;
       }
     #+end_src

     生成器语法像闭包, 其实现原理也和闭包类似. 
     eg: 11-62 中定义的生成器 gen, 将会由编译器自动生成一个匿名的枚举体, 然后为
     该枚举体自动实现 Generator.

     以下为等价代码, 实际编译器生成的代码要更复杂
     #+begin_src rust
       enum __Gen {
           // 初始状态
           Start,
           State1(State1),
           State2(State2),
           State3(State3),
           Done,
       }

       // 3 个结构体存储状态值
       struct State1 {
           x: u64,
       }
       struct State2 {
           x: u64,
       }
       struct State3 {
           x: u64,
       }

       // 为 __Gen 实现 `Generator`
       impl Generator for __Gen {
           // 指定类型
           type Yield = u64;
           // 指定类型
           type Return = u64;

           // 每次调用 `resume` fangfa, 其内部的 `self` 状态就会转移一次, 直到结束
           unsafe fn resume(&mut self) -> GeneratorState<u64, u64> {
               // 每次调用 `replace()` 方法, 都会将 `self` 的值替换为 `__Gen::Done`
               // 然后返回替换前的值, 匹配该结果, 达到状态转移的目的
               match std::mem::replace(self, __Gen::Done) {
                   __Gen::Start => {
                       ,*self = __Gen::State1(State1 { x: 1 });
                       // 状态转移
                       GeneratorState::Yielded(1)
                   }
                   __Gen::State1(State1 { x: 1 }) => {
                       ,*self = __Gen::State2(State2 { x: 2 });
                       GeneratorState::Yielded(2)
                   }
                   __Gen::State3(State3 { x: 3 }) => {
                       ,*self = __Gen::Done;
                       GeneratorState::Complete(4)
                   }
                   _ => panic("generator resumed after completion"),
               }
           }
       }

       fn main() {
           let mut gen = __Gen::Start;

           for _ in 0..4 {
               println!("{:?}", unsafe { gen.resume() });
           }
       }
     #+end_src
     
**** 生成器与迭代器
     生成器是非常有用的一个功能. 如果只关注计算的过程, 而不关心计算的结果, 则可
     以将 Return 设置为单元类型, 只保留 Yield 的类型, 也就是 ~Generator<Yield=T,
     Return=()>~, 那么生成器就可以化身为迭代器.

     *注意*: ~impl Trait~ 语法是在 Rust 2018 中加入的

     生成器的性能比迭代器要高. 因为生成器是一种 *延迟计算* 或 *惰性计算*, 它避免
     了不必要的计算, 只有在每次需要时才通过 yield 来产生相关的值.

**** 用生成器模拟 Future
     只关注生成器的计算过程而忽略结果, 生成器会化身为迭代器. 如果反过来, 不关心
     过程, 只关注结果, 则可以将 Yield 设置为单元类型, 只保留 Return 的类型, 也就
     是 ~Generator<Yield=(), Return=Result<T, E>>~, 生成器就可以化身为 Furture.

     因为不关心执行器过程中的状态, 所以只要还在计算过程中, 就返回 *Pending*, 一
     旦计算完成, 就返回 *Ready*.

     *Future* 是一种 *异步并发模式*, 它实际上是 *代理模式* 和 *异步并发* 的混合
     产物. Future 是对 "未来" 的一种代理凭证, 凭借这个凭证可以异步地在未来某个时
     刻得到确定的结果, 而不需要同步等待. 

     然而, 严格来说, 生成器属于一种 *半协程(Semi-Coroutine)*. 半协程是一种特殊的
     且能力较弱的协程, 它只能在生成器和调用者之间进行跳转, 而不能在生成器之间进
     行跳转. 所以, 要想支持完整的异步编程, 还需要在生成器的基础上进一步完善
     Future 并发模式.

*** Future 并发模式
    在实际的异步开发中, 需要将一个完整的功能切分为一个个独立的异步任务, 并且这些
    任务之间还可能彼此依赖, 一个任务的输出也许是另一个任务的输入. 如果想要合理地
    调度和高效地计算这些异步任务, 就需要一个完善的异步系统.

    因此, Rust 对 Future 异步并发模式做了一个完整的抽象, 包含在第三方库
    *futures-rs* 中. 该抽象主要包含三个核心部件:

    - *Future*: 基本的异步计算抽象单元.
    - *Executor*: 异步计算调度层
    - *Task*: 异步计算执行层
  
**** Future
     在 Rust 中, Future 是一个 trait.

     ~std::future~ 模块中 Future trait 的源码
     #+begin_src rust
       #[doc(spotlight)]
       #[must_use = "futures do nothing unless you `.await` or poll them"]
       #[stable(feature = "futures_api", since = "1.36.0")]
       #[lang = "future_trait"]
       #[rustc_on_unimplemented(label = "`{Self}` is not a future", message = "`{Self}` is not a future")]
       pub trait Future {
           #[stable(feature = "futures_api", since = "1.36.0")]
           type Output;

           #[lang = "poll"]
           #[stable(feature = "futures_api", since = "1.36.0")]
           // 该方法为 `Future` 核心, 是对 `轮询` 行为的一层抽象
           fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output>;
       }
     #+end_src

     在 Rust 中, 每个 ~Future~ 都需要使用 ~poll()~ 方法来轮询索要计算值得状态.
     该方法返回的 ~Pool~ 是一个枚举类型, 源码如下:
     #+begin_src rust
       #[must_use = "this `Poll` may be a `Pending` variant, which should be handled"]
       #[derive(Copy, Clone, Debug, Eq, PartialEq, Ord, PartialOrd, Hash)]
       #[stable(feature = "futures_api", since = "1.36.0")]
       pub enum Poll<T> {
           #[lang = "Ready"]
           #[stable(feature = "futures_api", since = "1.36.0")]
           // 准备好的状态抽象
           Ready(#[stable(feature = "futures_api", since = "1.36.0")] T),

           #[lang = "Pending"]
           #[stable(feature = "futures_api", since = "1.36.0")]
           // 未完成的状态抽象
           Pending,
       }
     #+end_src

**** Executor 和 Task
     Future 只是一个基本的异步计算抽象单元, 具体的计算工作还需要由 Executor 和
     Task 共同完成.

     在实际的异步开发中, 会遇到频繁复杂的异步任务, 还需要一个专门的调度器来对具
     体的任务进行管理统筹, 这个工具就是 Executor. 具体的异步任务就是 Task. 拿
     future-rs 来说, Executor 是基于线程池实现的.

     第三方库 future-rs 是由很多小的 crate 组合而成的, 其中 futures-executor 库
     专门基于线程池实现了一套 Executor.

     #+begin_example
       struct ThreadPool             struct PoolState            enum Message           struct Task
       state: Arc<PoolState>        tx: Sender<Message>            Run(Task)           future: FuturnObj
                                    rx: Receiver<Message>          Close              wake_handle: Arc<WakeHandle>




       Thread Pool   --------> new --------------> poolstate.work --------------> task.run
           |                                            ↑                            |
           |                                            |                            |
           |                                            |                            |
           |                                            |                            |
           |                                            |           Poll::Ready      |
           ↓                                            |    Complete <----- Future.poll_unpin   
         spawn_obj                                      |                            |
       PoolState: tx.send(Message::Run(task))           |                            |
           |                                            |                            | Poll::Pending
           |                                            |                            |
           |               futures::mpsc::channel ------                             |
           ------------->  | | | | | | | | | | | | <------------- wake <--------------
                                                     PollState: tx.send(Message::Run(task))
     #+end_example

     关键复合类型:
     
     - *ThreadPool*: 结构体, 包含了一个字段 state, 设置为 ~Arc<PoolState>~ 类型,
       是为了共享线程池内的线程信息
     - *PoolState*: 结构体, 包含了 tx 和 rx 两个字段, 分别是 ~Sender<Message>~
       和 ~Receiver<Message>~ 类型. 这两个类型看起来与 ~std::sync::mpsc~ 模块中
       定义额用于 Channel 通信的发送端和接收端类似相似, 但实际上是
       futures-channel 中定义额类型. 而 tx 和 rx 的作用是类似的, 同样用于
       Channel 通信.
     - *Message*: 枚举类型, 包含了两个枚举值, 其中最重要的就是 ~Run(Task)~. 该
       Message 用作发送到 Channel 中的消息. 这样的消息包含两种可能: 其中一种是允
       许 Task; 另一种是关闭线程池.
     - *Task*: 结构体, 包含了 ~future~ 和 ~wake_handle~ 两个字段, 分别为
       ~FutureObj~ 和 ~Arc<WeakHandle>~ 类型. 顾名思义, ~FutureObj~ 就是
       ~Future~ 对象, 它实际上是 ~futures-executor~ 中实现的自定义 Future 对象,
       它是对一个 Future trait 对象的一种包装; 而 ~WeakHandle~ 则是用来唤醒任务
       的句柄.

     Executor 提供了一个 *Channel*, 实际上就是一个任务队列. 开发者可以通过
     ThreadPool 提供的 ~spawn_obj()~ 方法将一个异步任务(Task)发送(send)到
     Channel 中. 实际上, 在 ~spawn_obj()~ 内部是通过 *PoolState* 结构体中存储的
     发送端 *tx* 将 ~Message::Run(task)~ 发送到 Channel 中的.
     
     通过 ~ThreadPool::new()~ 方法, 可以从线程池中调用一个线程来执行具体的任务.
     同时, 在该线程中也调用了 PoolState 结构体的 *work* 方法来消费 Channel 中的
     消息. 实际上, ~work()~ 方法是通过 PoolState 结构体中存储的接收端 *rx* 接收
     并消费 ~Message::Run(task)~ 的.

     就这样, 由 ~spawn_obj()~ 往 Channel 中发送消息, 由 ~work()~ 来接收并消费消
     息, 构成了一个完整的工作流程.

     当 ~work()~ 方法接收到 ~Message::Run(task)~ 之后, 会调用 *Task* 中定义的
     ~run()~ 方法来执行具体的 task. 在 ~run()~ 方法中, 调用存储于 task 实例中的
     ~FutureObj~ 类型值得 ~poll_unpin()~ 方法, 将会执行具体的 ~poll()~ 方法, 返
     回 Pending 和 Ready 两种状态. 如果是 Pending 状态, 则通过 task 实例存储的
     WakeHandle 句柄将此任务再次唤醒, 也就是重新将任务发送到 Channel 中, 等待下
     一次轮询; 如果是 Ready 状态, 则计算任务完成, 返回到上层进行处理.

     以上就是整个 futures-rs 核心工作机制的简要概括. 我们可以从图中整体上把握并
     建立 Rust 中 Future 异步开发的新值模型.

*** async/await
    迄今为止, 第三方库 futures-rs 经历了三个阶段的迭代. 在 0.1 版本中, 开发者可
    以通过 ~then()~ 和 ~and_then()~ 方法安排 Future 异步计算的执行顺序. 但是经过
    一段时间的用户反馈后, 发现这种方式会导致很多混乱的嵌套和回调链, 不利于人体工
    程学. 于是就引入了 async/await 解决方案. 又经过两个阶段后的重构为 0.3 版本.

    #+begin_src rust
      // futures-rs 0.1
      fn download_and_write_tweets(
          user: String,
          socket: Socket,
      ) -> impl Future<Output = io::Result<()>> {
          pull_down_tweets(user)
              .and_then(move |tweets| write_tweets(socket))
      }

      // futures-rs 0.3
      async fn download_and_write_tweets(
          user: &str,
          socket: &Socket,
      ) -> io::Result<()> {
          let tweets = await!(pull_down_tweets(user))?;
          await!(write_tweets(socket))
      }
    #+end_src

    Rust 当前以 async 关键字配合 await! 宏来提供 async/await 异步开发方案.

    *内容改动*:
    现版本 async/await 已进入 stable. [[https://github.com/rust-lang/rust/issues/50547][Link]]

    async/await 实际上是一种语法糖. async fn 会自动为开发者生成返回值是 ~impl
    Future~ 类型的函数.

**** async/await 实现原理
     Rust 不仅仅支持使用 async fn 定义异步函数, 还支持 async 块

     #+begin_src rust
       let my_future = async {
           await!(prev_async_func);
           println!("Hello from an async block");
       }
     #+end_src

     直接使用 async 块可以创建一个 Future. 实际上, 使用 async fn 定义函数在底层
     也是又 async 块来生成 Future 的

     由 async 块生成 Future 过程图:
     #+begin_example
       async ---------->   Generator -------------------> GenFuture --------------> impl Future
         |                     |                             |                           |
         |                     |                             |                           |
         |                     |                             |                           |
         |                     |                             |                           |
         |                     |                             |                           |
         |                     |                             |                           |
         ↓                     ↓                             ↓                           ↓
       keyword               yield              GenFuture<T: Generator<Yield = ()>>(T)
       async fn             resume()                  impl Future for GenFuture         poll
       async block                                          poll
                                                          resume()
     #+end_example

     async 关键字无论是用来定义异步函数, 还是定义异步块, 在 Rust 将代码解析为
     AST 之后, 在 HIR 层都会转换为 async 块的形式. 再将 async 块生成一个
     ~Generator<Yield=()>~ 类型的生成器来使用. 然后将该生成器通过单元结构体
     ~GenFuture~ 进行包装, 得到一个 ~GenFuture<T: Generator<Yield=()>>(T)~ 类型,
     最后为该 ~GenFuture~ 实现 Future

     为 ~GenFuture~ 实现 Future 源码
     #+begin_src rust
       impl<T: Generator<Yield = ()>> Future for GenFuture<T> {
           type Ouput = T::Return;

           fn poll(self: Pin<&mut Self>, lw: &LocalWaker)
                   -> Pool<Self::Output>
           {
               set_task_waker(lw, ||
                              // 此处调用了 `resume()` 函数,
                              // 此处代码等价于: `&mut self.0.resume()`
                              match unsafe { Pin::get_mut_unchecked(self).0.resume() }
                              {
                                  GeneratorState::Yielded(()) => Poll::Pending,
                                  GeneratorState::Complete(x) => Poll::Ready(x),
                              }
               )
           }
       }
     #+end_src
     

     接下来, 通过 ~std::future~ 模块中的 ~from_generator()~ 函数, 将实现了
     ~Future~ 的 ~GenFuture~ 作为返回值插入编译器生成的代码中.

     以上还需 ~await!~ 宏相互配合:
     #+begin_example
       async 块:
                   prev Task
           await! ---------->    Loop 块:
                                 if task::Poll::Ready
                                    break;
                                 else yield
     #+end_example

     ~async!~ 宏必须在 async 块中使用, 不能单独使用. 因为 ~await!~ 宏实际展开的
     代码要在 loop 循环中对轮询结果进行判断. 如果是 Ready 状态则跳出; 如果
     Pending 则生成 yield. 正是因为这个 yield, 才允许 async 块生成一个
     ~Generator<Yield = ()>~ 类型的生成器.

**** Pin 与 Unpin
     ~Pin<T>~ 是一个被定义域 ~std::pin~ 模块中的智能指针. 是在 Rust 2018 版本中
     新增的语法, 在 Rust 1.30 版本中定型为 ~Pin<T>~.

     *内容有改动*:
     生成器会由编译器生成相应地结构体来记录咋 U 你给他, 当生成器包含对本地变量的引
     用时, 该结构体会生成一种 *自引用结构体(Self-referential Struct)*. 
     
     代码清单 11-74(以上代码) 中生成器实例生成代码
     #+begin_src rust
       enum __Gen<'a> {
           Start,
           State1(State1<'a>),
           State2(State2),
           State3(State3),
           Done
       }

       struct State1<'a> { x: u64, xref_x: &'a u64 }

       impl<'a> Generator for __Gen<'a> {
           match std::mem::replace(self, __Gen::Done) {
               __Gen::Start => {
                   let x = 1;
                   let state1 = State1 { x: x, ref_x: &x };
                   ,*self = __Gen::State1(state1);
                   GeneratorState::Yielded(1)
               }
               __Gen::State1(State1 { x: 1, ref_x: &1 }) => {
                   ,*self = __Gen::State2(State2 { x: 2 });
                   GeneratorState::Yielded(2)
               }
           }
       }
     #+end_src

     ~Pin<T>~ 实际上是一个包装了指针类型的结构体, 其中指针类型是指实现了 ~Deref~
     的类型.

**** async/await 异步开发示例
     当然, 要想使用 Rust 进行异步开发, 需要配合使用标准库和第三方 futures-rs 库.
     这是因为标准库中引入了 Future 和 Task 两种类型, 是为了配合实现 async/await
     关键字. 而 Future 的大部分功能由 futures-rs 库可能会有所变化, 但是大体的原
     理和机制基本不会改变, 要变的也只能是 API.

     TODO: *警告*: 原始代码无法编译

     回顾整个异步开发机制, 实际上可以总结为 2 点:
     - 实现 Future, 构造异步任务
     - 生成 Task, 计算异步任务

     其中 Task 就像是在线程基础上又抽象出来的一层 "轻量级线程", 其使用语法也和线
     程差不多, eg: 在 futures-rs 库中内置了 ~spawn_obj()~ 和 ~spawn()~ 等函数来
     方便开发者将 Future 放入其中, 生成异步任务. 正因如此, 也有人将 Future 异步
     开发体系称为 *用户级线程*.

     在 futures-rs 库中还提供了很多方便组合或嵌套 Future 异步任务的各种组合函数.
** 数据并行
   随着人类前进的步伐, 越来越多的领域对计算的要求越来越高, 待解决问题的规模也在
   不断增加. 因此, 对并行计算的要求就越来越强烈.

   对于这个问题大致有两种解决方案: *任务并行(Task Parallelism)* 和 *数据并行
   (Data Parallelism)*. 任务并行是指将所需要执行的任务分配到多个核上; 数据并行是
   指将需要处理的数据分配到多个核上. 因为数据并行处理起来比任务并行更加简单和实
   用, 所以得到重点关注.

   按 Flynn 分类法, 将计算机系统结构分为 4 类:
   - SISD: 是指单指令单数句的单 CPU 机器, 它在单一的数据流上执行指令. 可以说, 任
     何单 CPU 的计算机都是 SISD 系统
     [Single Instruction Single Data]

   - MISD: 指有 N 个 CPU 的机器. 在这种架构下, 底层的并行实际上是指令级的并行,
     也就是说, 有多个指令来操作同一组数据. 但是 MISD 在实际中很少被用到
     [Multiple Instruction Single Data]     

   - SIMD: 指包含了多个独立的 CPU, 每一个 CPU 都有自己的存储单元, 可以用来存储数
     据. 所有的 CPU 可以同时在不同的数据上执行同一个指令, 也就是 *数据并行*. 这
     种架构非常实用, 便于算法的设计和实现
     [Single Instruction Multiple Data]

   - MIMD: 是应用最广泛的一类计算机体系. 该架构比 SIMD 结构更强, 通常用来解决
     SIMD 无法解决的问题
     [Multiple Instruction Multiple Data]

*** 什么是 SIMD
    SIMD 的思想容易理解.
    eg: 加法指令, 若采用 SISD 架构来计算, 则需要先访问内存, 取得第一个操作数, 然
    后再访问内存, 取第二个操作数, 最后才能进行求和运算. 若 采用 SIMD, 则可以一次
    性从内存中获得两个操作数, 然后执行求和运算.

    专业描述: SIMD 是一种采用一个控制器控制多个 CPU, 同时对一组数据(向量数据)中
    的每一个数据分别执行相同的操作而实现空间上数据并行的技术

**** 起源和历史
     SIMD 起源于美国首批超级计算机之一的 ILLIAC IV 大型机中, 它拥有 64 个处理器
     单元, 可以同时进行 64 个计算. 随着现代多媒体技术的发展, 各大 CPU 生产商陆续
     扩展了多媒体指令集, 允许这些指令一次处理多个数据. 最早的是 Intel 的
     *MMX(MultiMedia eXtensions)* 指令集, 包含了 57 个多媒体指令、8 个 64 位寄存
     器. 然后是 *SSE(Streaming SIMD Extensions)* 指令集, 弥补了 MMX 浮点数支持不
     足的问题, 并将寄存器的宽度扩展到 128 位, 引入了 70 个新指令. 接下来陆续出现
     了 SSE2、SSE3、SSE4、SS5 指令集.

     2011 年 Intel 发布了全新的处理器微架构, 其中增加了新的指令集 *AVX(Advanced
     Vector Extensions)*, 进一步把寄存器的宽带扩展到 256 位, 革新了指令格式, 支
     持三目运算.

**** 术语介绍
     按寄存器的宽度可以将 SIMD 看作不同的并行通道. eg: AVX-256 来说, 如果按 4 个
     64 位进行计算, 就可以看成是 4 个并行计算通道. 而在 SIMD 中并行计算可以分为
     多种计算模式, 其中有垂直计算和水平计算.

     #+begin_example
       X              x1  x2  x3  x4

       +              +   +    +   +

       Y              y1  y2  y3  y4
       ----------------------------------
       x+y           x1+y1 x2+y2 x3+y3 x4+y4
       普通指令       垂直计算的 SIMD 指令



       x1+x2  x3+x4  y1+y2  y3+y4
       ----   ----   -----  -----
        |       |      |      |
        |       |      |      |
        ↓       ↓      ↓      ↓
       x1+x2  x3+x4   y1+y2   y3+y4
       水平计算的 SIMD 指令
     #+end_example

     在垂直计算中, 每个并行通道都包含的待计算值称为标量值, 通道按水平方向进行组
     织. 将加法运算中的 X 和 Y 的数据在垂直方向上进行求和. 在垂直计算中, 每组计
     算的标量值都来自不同的源. 水平计算则是并行通道垂直组织, 依次对两个相邻通道
     的标量值进行求和. 在水平计算中, 每组计算的标量值都来自同一个源

     这种并行计算也是有限制的. 对于不同的指令集, 一次数据并行能接受的长度是固定
     的, eg: AVX-256, 能接受的长度为 256 字节.

     编写 SIMD 数据并行的代码称为 *向量化(Vectorization)*. 这是因为 *向量
     (Vector)* 是一个指令操作数, 包含一组打包到一维数组的数据元素. 大多数 SIMD
     指令都是对向量操作数进行操作的, 所以向量也被称为 *SIMD 操作数* 或 *打包操作
     数*. 数据并行意味着可以同时对向量的所有数据元素执行变换操作. 所以, 将编写程
     序使用向量处理器的过程, 称为向量化、矢量化或 SIMD 化. 向量化可以由编译器自
     动优化, 也可以由程序员手动指定.

*** 在 Rust 中使用 SIMD
    Rust 从 1.27 版本开始支持 SIMD, 并且默认为 x86 和 x86_64 目标启用 SSE 和
    SSE2 优化. Rust 基本支持市面上 90% 的 SIMD 指令集, 从 SSE 到 AVX-256. 不过目
    前还不支持 AVX-512.

    Rust 通过标准库 ~std::arch~ 和第三方库 stdsimd 结合的方式来支持 SIMD. Rust
    对 SIMD 的支持是属于比较底层的, 在标准库中支持多种 CPU 平台架构, 每种架构都
    有相应的模块, eg: ~srd::arch::x86~ 模块定义的就是与 x86 平台相关的 SIMD 指令.
    并且在平台模块中所有的函数都是 unsafe 的, 因为调用不支持的平台指令可能会导致
    未定义行为.

**** COMMENT SIMD 使用示例
**** 多入口文件的使用
     修改 ~Cargo.toml~ 文件, 在 ~\[[bin]\]~ 属性中手动指定 *path* 和 *name* 后,
     通过 ~cargo run --bin name~ 即可执行指定的入口文件

**** SIMD 命名说明
     以 x86 平台为例, 主要支持以下几种类型:

     - *_m128i*: 128 位宽度的整数向量类型
     - *_m128*: 128 位宽度的 4 组 f32 类型
     - *_m128d*: 128 为宽度的 2 组 f64 类型
     - *_m256i*: 256 位宽度的整数向量类型
     - *_m256*: 256 位宽度的 8 组 f32 类型
     - *_m256d*: 256 为宽度的 4 组 f64 类型

     以 ARM 平台为例:
     - *float32x2_t*: 64 位宽度的 2 组打包 f32 向量类型
     - *float32x4_t*: 128 位宽度的 2 组打包 f32 向量类型
     - *int32x2_t*: 64 位宽度的 2 组打包 i32 向量类型
     - *int32x4_t*: 128 位宽度的 2 组打包 i32 向量类型

     同理, 函数命名也有规则. ~std::arch::x86::_mm256_add_epi64~ 为例, 以
     ~_mm256_~ 开头的代表 AVX 指令, 然后是随之对应的指令操作(add, mul, abs 等),
     最后是使用的类型 (_pd 用于 32 位浮点数, _epi32 用于 32 为整数).

**** 第三方库介绍
     除了官方提供的第三方库 stdsimd, 社区中比较突出的是 faster 和 simdeez. 这两
     个库的特色是相比 stdsimd 做了更进一步的抽象, 对开发者友好.

     以 faster 为例, 封装了很多函数, 开发者不需要记忆标准库中各个平台下函数的命
     名规则.
