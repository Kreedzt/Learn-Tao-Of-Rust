* 安全并发  
** 通用概念
   并发(Concurrency)的概念很容易和并行(Parallelism)混淆, 事实上它们是不同的概念.

   谷歌著名工程师罗布派克(Rob Pike)说过: "并发就是 *同时应对(Dealing With)* 多件
   事情的能力, 并行是 *同时执行(Doing)* 多件事情的能力".

   将任务分配在不同的时间片内交替完成就是 *并发, 关注点在于任务的切分, 这是一种
   逻辑架构、一种能力*. 每个单位都是事情执行的个体, 相互无影响, 各自独立工作, 这
   就是 *并行, 关注点在于同时执行, 这是具体的实施状态*. 并发并不要求一定要并行,
   利用并并发可以制造出并行的假象.

   在实际编程中, 对任务进行分解才是重点, 一旦将任务分解正确, 到了执行层面, 并行
   就会自然发生, 也容易保证程序的正确性. 如何分解任务是并发设计要解决的问题, 所
   以, 通过更关注并发而非并行.

   使用并发主要出于 2 个主要原因: *性能* 和 *容错*.

   随着多核计算机的普及, 为了利用日益增长的计算能力, 就必须要编写并发程序. 并发
   编程越来越受重视, 甚至可能成为一种新的编程范式, Go 语言的横空出世就证明了这一
   点. 另外, 并发编程还可以将程序分为不同的功能区域, 让程序更容易理解和测试, 从
   而减少程序出错的可能性.

   在计算机中, 通常使用一些独立的运行实体对并发进行支持, 分为如下两类:
   - 操作系统提供的进程和线程
   - 编程语言内置的用户级线程

*** 多进程和多线程
    进程是资源分配的最小单元, 线程是程序执行时的最小单元.

    从操作系统的角度来看, 进程代表操作系统分配的内存、CPU 时间片等资源的基本单位,
    它为程序提供基本的运行环境. 不同的应用程序可以按业务划分为不同的进程. 从用户
    的角度来看, 进程代表运行中的应用程序, 它是动态条件下由操作系统维护的资源管理
    实体, 而非静态的应用程序文件. 每个进程都享有自己独立的内存单元, 从而极大地提
    高了程序的运行效率.

    可以使用多进程来提供并发, eg: Mater-Worker 模式, 由 Master 进程来管理 Worker
    子进程, Worker 子进程执行任务. Master 和 Worker 之间通常使用 Socket 来进行进
    程间通信(IPC). 这样的好处就是具有极高的健壮性, 当某个 Worker 子进程出现问题
    时, 不会影响到其他子进程. 但缺点也非常明显, 其中最让人诟病的是进程会占用相当
    可观的系统资源. 除此之外, 进程还有切换复杂、CPU 利用率低、创建和销毁复杂等缺
    点.

    为了寻求比进程更小的资源占用, 线程应运而生. 线程是进程内的实体, 它无法独立存
    在, 必须依靠进程, 线程的资源资源都来源于进程, 包括内存. 每个进程至少拥有一个
    线程, 这个线程就是主线程. 每个进程也可以生成若干个线程来并发执行多任务, 但只
    能有一个主线程, 线程和线程之间可以共享同一个进程内的资源. 一个线程也可以创建
    或销毁另一个线程, 所以线程会有创建、就绪、运行、阻塞和死亡 5 种状态. 每个线
    程也有自己独享的资源, eg:线程栈. 线程和进程一样, 都受操作系统内核的调度. 线
    程拥有进程难以企及的优点, eg: 占用内存少, 切换简单, CPU 利用率搞, 创建/销毁
    简单、快速等. 线程的缺点也是非常明显的, eg: 编程相当复杂, 调试困难等. 正是由
    于这些缺点, 导致多线程并发编程成为众多开发者心中的痛.

*** 事件驱动、异步回调和协程
    多线程虽然比多进程更省资源, 但其依然存在昂贵的系统内核调度代价. 互联网的发展
    让这个问题更加突出. 在服务器领域有一个非常出名的 *C10K* 问题, 主要是指单台服
    务器要同时处理 10K 量级的并发连接, 解决此问题最直接的就是多进程(线程)并发,
    每个进程(线程)处理一个连接. 但是, 这种处理方式显然是有问题的, 因为服务器根本
    没有这么多资源可以分配给如此多的进程(线程).

    为了解决 C10K 问题, *事件驱动编程* 应运而生, 最知名的就是 Linux 退出的
    *epoll* 技术. 事件驱动也可以称为事件轮询, 它的优点在于编程更加容易, 不用做并
    发设计的考虑, 不需要引入锁, 不需要考虑内部调度, 只需要依赖于事件, 最重要的是
    不会阻塞. 所以它可以很方便地和编程语言相集成, eg: Node.js, 也就是第一个事件
    驱动编程模型语言. 在 Node.js 中, 仅仅使用单线程就可以拥有强大的并发处理能力,
    其力量来源就是 *事件驱动* 和 *异步回调(Callback)*. 通过内置的事件循环机制,
    不断地从事件队列中查询是否有事件发生, 当读取到时间时, 就会调用和此事件关联的
    回调函数, 整个过程是非阻塞的.

    事件驱动和回调函数虽然解决了 C10K 的问题, 但是对于开发者来说还远远没有那么完
    美. 问题就出在回调函数上面, 如果编写业务比较复杂的代码, 开发者将陷入 "*回调
    地狱(Callback Hell)*" 中, 代码中充斥着各种回调嵌套, 很快就会变成一团乱麻. 回
    调函数的这种写法, 并不符合人类的思维直觉, 所以使用起来比较痛苦.

    为了避免 "回调低于", 不停地有新方案被提出, eg: *Promise* 和 *Future*, 这两种
    方案从不同的角度来处理回调函数. Promise 站在任务处理者的角度, 将异步任务完成
    或失败的状态标记到 Promise 对象中. Future 则站在任务调用者的角度, 来检测任务
    是否完成, 如果完成则直接获取结果, 如果未完成则阻塞直到获取到结果, 或者编写回
    调函数避免阻塞, 根据相应地完成状态执行此回调函数. 虽然 Promise 和 Future 可
    以进一步缓解回调函数的问题, 但它们还是不够完美, 代码中依然充斥着各种冗余.

    为了进一步完善基于事件驱动的编程体验, 一种叫作 *协程* 的解决方案浮出水面. 协
    程的概念很古老, 甚至可以追溯到 20 世纪 60 年代的 COBOL 语言, 但是因为时代使
    然, 协程并未称为像线程那样的通用编程元素. 然而, 随着事件编程的兴起, 协程又有
    了用武之地.

    协程为协同任务提供了一种抽象, 这种抽象本质上就是控制流的出让和恢复. 协程的这
    种机制, 正好符合现实世界中人类异步处理实物的直觉. eg: 程序员可以暂停自己写代
    码的过程, 进行场景切换, 去参加产品经理组织的会议, 当会议结束后, 再切回之前的
    场景继续编写代码. 虽然处理了不同的事件, 但对于程序员来说, 都是顺序执行的. 可
    以看出, 协程和事件驱动属于绝配. 当事件来临时, 出让当前的控制权, 切换场景, 完
    成该事件, 然后再切换回之前的场景, 恢复之前的工作. 如果说事件驱动编程和异步回
    调是站在开发者的角度来进行编程的. 开发者将自身代入各事件中, 看上去就是顺序执
    行的. 总的来说, 协程可以让开发者用写同步(顺序)代码的方式编写可异步执行的代码.

    在现代编程语言中, 实现协程的方法有很多, 但其中的区别只在于是否有适合的应用场
    景. 场景的有 Go 语言的 *go 程(goroutines)*, Erlang 语言的 *轻量级线程(LWP)*.
    另外, 像 Python、Ruby、JavaScript 这样的语言也实现了协程, 当然 Rust 语言也支
    持协程. 协程是以线程为龙骑的, 协程的特点是内存占用比线程更小, 上下文切换的开
    销更小、没有昂贵的系统内核调度, 这也意味着协程的运行效率更加高效. 协程非常轻
    量, 也被称为用户态线程, 所以可大量使用. 但协程也不是 "银弹", 它虽然充分挖掘
    了单线程的利用率, 在单线程下可以处理高并发 I/O, 但却无法利用多核.

    当然, 可以将协程和多线程配合使用, 来充分利用多核. 但是, 从单线程迁移到多线程
    并不会只带来好处, 它也会带来更多的风险.

*** 线程安全
    线程其实是对底层硬件运行过程的直接抽象, 这种抽象方式既有优点又有缺点. *优点*
    在于很多编程语言都对其提供了支持, 并且没有对其使用方式加以限制, 开发者可以自
    由地实现多线程并发程序, 充分利用多核. *缺点* 包含两个方面: 一方面, 线程的调
    度完全由系统内核来控制, 完全随机, 这就导致多个线程的运行顺序是完全无法预测的,
    有可能产生奇怪的结果; 另一方面, 编程正确的多线程并发程序对开发者的要求太高,
    对多线程编程没有充足知识储备的开发者很容易写出满是 Bug 的多线程代码, 并且还
    很难重现和调试.

    多线程存在问题主要是因为资源共享, eg:　共享内存、文件、数据库等. 实际上, 只
    有当一个或多个线程对这些资源进行写操作时才会出现问题, 如果只读不写, 资源不会
    发生变化, 自然也不会存在安全问题. 假如一个方法、数据结构或库在多线程环境中不
    会出现任何问题, 则可以称之为 *线程安全*.

    所以, 多线程编程的重点就是如何写出线程安全的代码.

**** 竞态条件与临界区
     要想写出线程安全的代码, 必须先了解安全的边界在哪里.

     在单线程环境中, ~unsafe_seq()~ 函数不会有任何问题, 但是将其放到多线程环境中,
     则会有问题. 实际上, ~V+=1~ 操作上在运行过程中并非单个指令, 而是可以分为三
     步:
     1) 从内存中将 ~V~ 的初始值放入寄存器中
     2) 将寄存器中的 ~V~ 的值加 1.
     3) 将加 1 后的值写入内存.

     这三步操作无法保证在同一个线程中被一次执行完成. 因为系统内核调度的存在, 很
     有可能在线程 A 执行第二步操作之后, 从线程 A 切换到了线程 B, 而线程 B 此时并
     不知道线程 A 已经执行了第一步操作, 它又重复将 ~V~ 的初始值放入寄存器中, 当
     又切换回线程 A 后, 线程 A 会继续执行第三步操作, 此时就从寄存器中读取了错误
     的值.

     这种常见的并发安全问题, 叫作 *竞态条件(Race Condition)*. 当某个计算的正确性
     取决于多个线程交替执行的顺序时, 就会产生竞态条件. 也就是说, 想计算出正确的
     结果, 全靠运气. 最常见的竞态条件类型是: "*读取-修改-写入*" 和 "*先检查后执
     行*" 操作. 代码 11-1 展示的就是 "读取-修改-写入" 竞态条件; 而 "先检查后执行
     " 竞态条件则出现在需要判断某个条件为真之后才采取相应地动作时. 产生竞态条件
     的区域, 就叫做 *临界区*.

     在代码清单 11-1 中展示的代码也同时引起了 *数据竞争(Data Race)*. "数据竞争"
     这个术语很容易和竞态条件相混淆. 当一个线程写一个变量而另一个线程读这个变量
     时, 如果这两个线程没有进行同步, 则会发生数据竞争. 因为竞态条件的存在, 读操
     作很可能在操作之前就完成了, 那么读到的数据就是错误的.
     *并非所有的竞态条件都是数据竞争, 也并非所有的数据竞争都是竞态条件*.

     简单来说, 当有多个线程对同一个变量同时进行读写操作, 且至少有一个线程对该变
     量进行写操作时, 则会发生数据竞争. 也就是说, 如果所有的线程都是读操作, 则不
     会发生数据竞争. 数据竞争的后果是早成该变量的值不可知, 多线程程序的运行结果
     将完全不可预测, 甚至直接崩溃.

     11-2 用于转账操作的函数(伪代码):
     #+begin_example
       trans1(amount, account_from, account_to) {
           if (account_from.balance < amount) return FALSE;
           account_to.balance += amount;
           account_from.balance -= amount;
           return TRUE;
       }
     #+end_example
     
     在多线程环境中, 这个伪代码示例既包含了竞态条件, 又包含了数据竞争, 转账结果
     将不可预测. 为了解决该问题, 采用某种同步操作, eg: 使用互斥量(Mutex)或某种禁
     用中断操作的事务, 将包含数据竞争的操作变为原子性操作.
     
     11-3 改进转帐操作的函数:
     #+begin_example
       trans2(amount, account_from, account_to) {
           atomic { bal = account_from.balance; }
           if (bal < amount) return FALSE;
           atomic { account_to.balance += amount; }
           atomic { account_from.balance -= amount; }
           return TRUE;
       }
     #+end_example

     使用 atomic 块表示将其范围内的操作变为原子性的某种手段. 总之, 现在数据竞争
     被消除了. 但还存在竞态条件, 不同的线程依然可以乱序执行代码第 4 行和第 5 行
     的操作. 这个交易函数 ~trans2()~ 的正确性, 在不同的线程执行顺序下, 会出现不
     同的结果. 所以还需要继续对其改进.

     11-4 继续改进转账操作的函数
     #+begin_example
       trans3(amount, account_from, account_to) {
           atomic {
               if (account_from.balance < amount) return FALSE;
               account_to.balance += amount;
               account_from.balance -= amount;
               return TRUE;
           }
       }
     #+end_example

     在 ~trans3()~ 函数中, 通过 atomic 块将 整个函数的执行过程赋予原子性, 这样就
     完全消除了数据竞争和竞态条件. 可以看出, *消除竞态条件的关键在于判断出正确的
     临界区*.

     还可以对其进一步改进, 创建一个有数据竞争但无竞态条件的函数.
     11-5 进一步改进转账操作的函数
     #+begin_example
       trans4(amount, account_from, account_to) {
           account_from.activity = true;
           account_to.activity = true;
           atomic {
               if (account_from.balance < amount) return FALSE;
               account_to.balance += amount;
               account_from.balance -= amount;
               return TRUE;
           }
       }
     #+end_example
     
     在 ~trans4()~ 函数中增加了两行伪代码, 如第二行和第三行所示, 这两行代码表示
     这两个账号上会出现某些状态变更的行为. 这两行代码会出现数据竞争, 但不存在竞
     态条件. 但这里的数据竞争并不会影响到交易行为的正确性, 所以是无害的.

     通过上面的 4 段伪代码, 刻意区分了数据竞争和竞态条件之间的区别. 在多线程编程
     中, 数据竞争是最常见、最严重、最难调试的并发问题之一, 可能会引起崩溃会内存
     不安全.

     接下来看看 Rust 多线程代码实际产生竞态条件和数据竞争问题的例子(11-6)

     正常情况下, 对该段代码进行编译执行, 期待的数据结果是 main 主线程和 child 子
     线程一共输出 0 ~ 20 的数字. 但实际执行多次会看到不同的输出结果, 基本会出现
     以下两种情况:
     - 在 main 主线程输出的结果中会莫名其妙地少一位, 并不是 0 ~ 10 的连续值
     - child 子线程输出的结果和 main 主线程输出的结果有重复

     可以看出, 该段代码在多线程环境中的行为和结果完全无法预测, 完全无法保证正确
     性.

**** 同步、互斥和原子类型
     综上所述, 产生竞态条件主要是因为线程乱序执行, 发生数据竞争主要是因为多线程
     同时对桶一块内存进行读写. 那么, 要消除竞态条件, 只需要保证线程按指定顺序来
     访问即可. 要避免数据竞争, 只需要保证相关数据结构操作的原子性即可. 所以, 很
     多编程语言都通过提供同步机制来消除竞态条件, 使用互斥和原子类型来避免数据竞
     争.

     同步是指保证多线程按指定顺序执行的手段. 互斥是指用一时刻只允许单个线程对临
     界资源进行访问, 对其他线程具有排他性, 线程之间的关系表示为互斥. 而原子类型
     是指修改临界数据结构的内部实现, 确保对它们做任何更新, 在外界原来都是原子性
     的, 不可中断.

     通常可以使用 *锁*, *信号量(Semaphores)*, *屏障(Barrier)* 和 *条件变量
     (Condition Variable)* 机制来实现同步. 根据不同的并发场景分为很多不同类型的
     锁, 有互斥锁(Mutex)、读写锁(RwLock)和自旋锁(Spinlock)等. 锁的作用是可以保护
     临界区, 同时达到同步和互斥的效果. 不同的锁表现不同, 比如互斥锁, 每次只允许
     单个线程访问临界资源; 读写锁可以同时支持多核线程读或单个线程写; 自旋锁和互
     斥锁类似, 但当获取锁失败时, 它不会让线程睡眠, 而是不断地轮询直到获取成功.

     *信号量* 可以在线程间传递信号, 也叫作信号灯, 它可以为资源访问进行计数. 信号
     量是一个非负整数, 所有通过它的线程都会将该整数 -1, 如果信号量为 0, 那么其他
     线程只能等待. 当线程执行完毕离开临界区时, 信号量会再次 +1. 当信号量只允许设
     置 0 和 1 时, 效果相当于互斥锁.

     *屏障* 可以让一系列线程在某个指定的点进行同步. 通过让参数指定屏障区域的线程
     等待, 知道所有参与线程都到达指定的点. 而 *条件变量* 用来自动阻塞一个线程,
     直到出现指定的条件, 通常和互斥锁配合使用.

     通过一些锁机制, eg: 互斥锁, 也可以用来避免数据竞争. 本质上, 是通过锁来保护
     指定区域的原子性的. 有些语言也提供了原子类型来保证原子性, eg: Java、C++ 以
     及 Rust. 具有原子性的操作一定是不可分割的, 要么全部完成, 要么声明都不做. 原
     子类型使用起来简单, 但其背后的机制缺一点也不简单, 了解其背后的机制有助于更
     好地使用原子类型.
     
**** 原子类型与多线程内存模型
     在计算机中程序需要经过 CPU、CPU 多级缓存和内存等协同工作才能顺利执行, 在这
     种体系结构之下, 如果是多核系统, 其中一个 CPU 核心修改了变量, 那么如果通知其
     他核心是一个重要的问题. 并且为了提高性能, 现代处理器和编程语言的编译器都对
     程序进行了极度优化, eg: *乱序执行* 和 *指令重排*, 所以机器并非按照实际编写
     的那样来执行. 在多线程编程中, 只有保持顺序一致性, 才能保证程序的正确性. 所
     谓 *顺序一致性*, 主要约定了 2 件事:
     - 在单线程内部指令都是按程序确定的顺序来执行的
     - 多线程程序在执行过程中虽然是交替执行的, 但从全局来看, 也是按某种确定的顺
       序来执行的.

     显然, 在硬件层面并没有支持顺序一致性, 所以需要编程语言和计算机系统(包括编译
     器、CPU 等)  之间达成 "契约", 该契约规定了多线程访问同一个内存位置时的语义,
     以及某个线程对内存位置的更新何时才能被其他线程看到. 这个契约就是 *多线程内
     存模型*. 通过该内存模型, 程序员就可以使用编程语言提供的同步原语(eg: C++ 和
     Rust 提供的 Atomic 类型)来保证多线程下的顺序一致性, 这也是无锁并发编程的基
     础.

     Rust 的多线程内存模型来源于 C++ 11, 而 C++ 11 中实现的 Atomic 类型是通过
     store 和 load 这两个 CPU 指令进行数据存取(寄存器和内存之间)的, 并且额外接受
     一个 *内存序列(Memory Order)* 作为参数. C++ 11 支持 6 种内存排序约束, 而
     Rust 是基于 LLVM 实现的, 所以 Rust 通过 LLVM 原子内存排序约束来实现不同级别
     的原子性.

**** 为什么多线程这么难
     既然有了这么多避免竞态条件和数据竞争的手段, 那么为什么提到多线程还会让广大
     开发者心生恐惧呢? 主要由以下几点原因:

     - 虽然可以使用锁来同步, 但卡覅啊中有可能忘记加锁
     - 即使没有忘记加锁, 也可能出现死锁的情况
     - 多线程程序难以调试, 如果出现了问题很难再现

     总的来说, 主要因为开发者自身很难驾驭多线程编程. 即便是技艺高超的开发者, 也
     难以保证写出没有问题的多线程代码. 难以驾驭背后的原因下雨, 开发者总是有意无
     意地将不改共享的数据错误地共享, 将其暴露在多个线程可以操作的危险区. Rust 语
     言的出现正是要解决这个问题的.
** 多线程并发编程
   Rust 为开发者提供的并发编程工具和其他语言类似, 主要包括如下两个方面:
   - *线程管理*: 在 ~std::thread~ 模块中定义了管理线程的各种函数和一些底层同步原
     语.
   - *线程同步*: 在 ~std::sync~ 模块中定义了锁、Channel、条件变量和屏障

*** 线程管理
    Rust 中的线程是本地线程, 每个线程都有自己的栈和本地状态. 
    
    ~move~ 关键字用于强制转移所有权.

    子线程的 ~join()~ 方法可以让 ~main~ 主线程等待这些子线程都执行完毕.

    如果想要多个线程协作, 通常会使用 ~join()~ 方法来指定一个线程等待其他线程执行
    完之后再执行它自己的任务.

    当 thread1 中调用 thread2 的 ~join()~ 方法时, 则 thread1 就会在调用的那一刻
    等待 thread2, 并且 *阻塞自身*, 只有 thread2 执行完毕后才继续执行 thread1 中
    的任务.

**** 定制线程
     直接使用 ~thread::spawn~ 生成的线程, 默认没有名称, 并且栈大小默认为 2MB. 如
     果想为线程指定名称或者修改默认栈大小, 则可以使用 ~thread::Builder~ 结构体来
     创建可配置的线程.

     通过 ~Builder::new()~ 方法生成的 ~Builder~ 实例, 然后分别将事先声明好的名称
     和栈大小参数传入 ~name()~ 和 ~stack_size()~ 方法中, 就可以生成指定名称和栈
     大小的线程.

     *注意*: 主线程的大小与 *Rust 语言无关*, 这是因为主线程的栈实际上就是进程的
     栈, 由操作系统来决定. 修改所生成线程的默认值也可以通过指定环境变量
     *RUST_MIN_STACK* 来完成, 但是它的值会被 ~Builder::stack_size()~ 覆盖掉.

     *注意*: ~thead::spawn~ 方法返回的是 ~JoinHandle<T>~ 类型, 而 ~Builder~ 的
     ~spawn~ 方法返回的是 ~Result<JoinHandle<T>>~ 类型, 所以这里需要加
     ~unwrap()~ 方法. ~JoinHandle<T>~ 代表线程与其他线程 ~join()~ 的权限.

**** 线程本地存储
     *线程本地存储(Thread Local Storage, TLS)* 是每个线程独有的存储空间, 在这里
     可以存放其他线程无法访问的本地数据.

     ~thread::local!~ 宏辉生成类型为 ~thread::LocalKey~ 的实例.

     当前代码实例为 FOO. 该实例是一个结构体, 提供了一个 ~with()~ 方法, 可以通过
     给该方法传入闭包来操作线程本地存储中包含的变量.

     在标准库中很多数据结构实现都使用了 ~thread_local!~ 宏来定义单个线程内的一些
     独享数据, eg: ~HashMap~.

**** 底层同步原语
     在 ~std::thread~ 模块中还提供了一些函数, 用来支持底层同步原语, 主要包括
     ~park()/unpark()~ 和 ~yield_now()~ 函数.

     ~std::thread::park()~ 函数提供了阻塞线程的基本能力, 而
     ~std::thread::thread::unpark()~ 函数可以将阻塞的线程重启. 可以利用 ~park()~
     和 ~unpark()~ 函数来方便地创建一些新的同步原语, 比如某种锁.
     *注意*: ~park()~ 函数并 *不能永久地阻塞线程*, 也可以通过
     ~std::thread::park_timeout()~ 来显式指定阻塞超时时间.

     *注意*: 千万不要使用 ~sleep()~ 来进行任何线程同步的操作, 它并不会保证线程执
     行的顺序.

     除了阻塞/重启的同步原语, ~std::thread~ 模块还提供了主动让出当前线程时间片的
     函数 ~yield_now()~. 众所周知, 操作系统是抢占式调度线程的, 每个线程都有固定
     的执行时间片, 时间片是由操作系统切分好的, 以便每个线程都可以拥有公平使用
     CPU 的机会. 但是有时开发者明确知道某个线程在一段时间内会什么都不做, 为了节
     省计算时间, 可以使用 ~yield_now()~ 函数自动放弃当前操作系统分配的时间片, 让
     给其他线程执行.
          
*** Send 和 Sync
    从 Rust 提供的线程管理工具来看, 并没有发现什么特殊的地方, 和传统语言的线程管
    理方式非常相似. 那么, Rust 是如何做到之前宣称的那样默认线程安全的呢? 这要归
    功于 ~std::marker::Sync~ 两个特殊的内置 trait. ~Send~ 和 ~Sync~ 被定义于
    ~std::marker~ 模块中, 它们属于 *标记 trait*, 其作用如下:

    - *实现了 Send 的类型, 可以安全地在线程间传递所有权*. 也就是说, 可以跨线程移
      动
    - *实现了 Sync 的类型, 可以安全地在线程间传递不可变借用*. 也就是说, 可以跨线
      程共享.

    这两个标记 trait 反映了 Rust 看待线程安全的哲学: *多线程共享内存并非线程不安
    全问题所在, 问题在于错误地共享数据*. 通过 Send 和 Sync 将类型贴上 "标签", 由
    编译器来识别这些类型是否可以在多个线程之间移动或共享, 从而做到在编译期就能发
    现线程不安全的问题. 和 Send/Sync 相反的标记是 *!Send/!Sync*, 表示不能在线程
    间安全传递的类型.

    ~std::thread::spawn~ 函数的源码实现:
    #+begin_src rust
      #[stable(feature = "rust1", since = "1.0.0")]
      pub fn spawn<F, T>(f: F) -> JoinHandle<T>
      where
          F: FnOnce() -> T,
          // 闭包 F 与 闭包的返回类型 T 都加上了 `Send` 和 `'static` 限定
          F: Send + 'static,
          T: Send + 'static,
      {
          Builder::new().spawn(f).expect("failed to spawn thread")
      }
    #+end_src

    ~Send~ 限定了闭包的类型以及闭包的返回值都必须是实现了 ~Send~ 的类型, 只有实
    现了 ~Send~ 的类型才可以在线程间传递. 而闭包的类型是和捕获变量相关的, 如果捕
    获变量的类型实现了 ~Send~, 那么闭包就实现了 ~Send~.

    而 ~'static~ 限定表示类型 ~T~ 只能是 *非引用类型(除 ~&'static~ 之外)*. 其实
    这个很容易理解, 闭包在线程间传递, 如果直接携带了引用类型, 生命周期将无法保证,
    很容易出现悬垂指针, 造成内存不安全. 这是 Rust 绝对不允许出现的情况.

    如果是不可变的变量, 可以通过 ~Arc<T>~ 来共享. ~Arc<T>~ 是 ~Rc<T>~ 的线程安全
    版本, 因为在 ~Rc<T>~ 内部并非使用原子操作, 所以在多个线程之间共享会出现安全
    问题; 而在 ~Arc<T>~ 内部使用了原子操作, 所以默认线程安全.

    源码中为 ~Arc<T>~ 实现 ~Send~ 和 ~Sync~
    #+begin_src rust
      #[stable(feature = "rust1", since = "1.0.0")]
      unsafe impl<T: ?Sized + Sync + Send> Send for Arc<T> {}
      #[stable(feature = "rust1", since = "1.0.0")]
      unsafe impl<T: ?Sized + Sync + Send> Sync for Arc<T> {}
    #+end_src

    可以看出, 只要 T 是实现了 ~Send~ 和 ~Sync~ 的类型, 那么 ~Arc<T>~ 也会实现
    ~Send~ 和 ~Sync~. 值得注意的是, ~Send~ 和 ~Sync~ 这两个 trait 是 unsafe 的,
    这意味着如果开发者为自定义类型手动实现这两个 trait, 编译器是 *不保证线程安全
    的*. 实际上, 在 Rust 标准库 ~std::marker~ 模块内部, 就为所有类型默认实现了
    ~Send~ 和 ~Sync~, 就是为 *所有类型设定好了默认的线程安全规则*.

    #+begin_src rust
      unsafe impl Send for .. {}
      impl<T: ?Sized> !Send for *const T { }
      impl<T: ?Sized> !Send for *mut T { }
      unsafe impl Sync for .. { }
      impl<T: ?Sized> !Sync for *const T { }
      impl<T: ?Sized> !Sync for *mut T { }
      mod impls {
          unsafe impl<'a, T: Sync + ?Sized> Send for &'a T { }
          unsafe impl<'a, T: Send + ?Sized> Send for &'a mut T { }
      }
    #+end_src
    

    第 1 行和第 4 行使用了一种特殊的语法, 分别表示为所有类型实现了 ~Send~ 和
    ~Sync~. 这里要注意 ~Send~ 和 ~Sync~ 本身只是标记 trait, 没有乐乐虎没咯嗯的方
    法. 如果想使用第 1 行和第 4 行这样的语法, *必须满足 2 个条件*:
    - impl 和 trait 必须在同一个模块中
    - 在该 trait 内部不能有任何方法

    第 2 行和第 3 行以及第 5 行和第 6 行分别为 ~*const T~ 和 ~*mut T~ 类型实现了
    ~!Send~ 和 ~!Sync~, 表示实现这两种 trait 的类型不能在线程间安全传递.

    第 7 ~ 10 行, 分别为 ~&'a T~ 和 ~&' a mut T~ 实现了 ~Send~, 但是对 ~T~ 的限
    定不同. ~&'a T~ 要求 ~T~ 必须是实现了 ~Sync~ 的类型, 表示 *只要实现了 Sync
    的类型, 其不可变借用就可以安全地在线程间共享*; 而 ~&'a mut T~ 要求 ~T~ 必须
    是实现了 ~Send~ 的类型, 表示 *只要实现了 ~Send~ 的类型, 其可变借用就可以安全
    地在线程间移动*.

    除在 ~std::marker~ 模块中标记的上述未实现的 ~Send~ 和 ~Sync~ 的类型之外, 在
    其他模块中也有. eg: 在 ~Cell~ 和 ~RefCell~ 都实现了 ~!Sync~, 表示无法跨线程
    共享; eg2: ~Rc~ 实现了 ~!Send~, 表示无法跨线程移动.

    通过 ~Send~ 和 ~Sync~ 构建的规则, 编译器就可以方便地识别线程安全问题.

    ~Arc<T>~ 默认是不可变的, 当想要使用具备内部可变性的类型时, 可以使用 ~Cell~,
    ~RefCell~.

    ~RefCell<String>~ 没有实现 ~Sync~, 但是 ~Arc~ 只支持实现 ~Sync~ 的类型. 同时,
    错误信息也会提示 ~RefCell<String>~ 不能在线程间安全共享.

*** 使用锁进行线程同步
    要修复 11-20 中的错误, 只需要使用支持跨线程安全共享可变变量的容器即可, 所以
    可以使用 Rust 提供的 ~Mutex<T>~ 类型.

**** 互斥锁(Mutex)
     ~Mutex<T>~ 其实就是 Rust 实现的互斥锁, 用于保护共享数据. 如果类型 ~T~ 实现
     了 ~Send~, 那么 ~Mutex<T>~ 会自动实现 ~Send~ 和 ~Sync~. 在互斥锁的保护下,
     每次只能有一个线程有权限访问数据, 但在访问数据之前, 必须通过调用 ~lock()~
     方法阻塞当前线程, 直到得到互斥锁, 才能获得访问权限.

     ~Mutex<T>~ 类型实现的 ~lock()~ 方法会返回一个 ~LockResult<MutexGuard<T>>~
     类型, ~LockResult<T>~ 是 ~std::sync~ 模块中定义的错误类型, ~MutexGuard<T>~
     基于 *RAII* 机制实现, 只要超出作用域范围就会自动释放锁. 另外, ~Mutex<T>~ 也
     实现了 ~try_lock()~ 方法, 该方法再获取锁的时候不会阻塞当前线程, 如果得到锁,
     就返回 ~MutexGuard<T>~, 反之返回 ~Err~.

**** 跨线程恐慌和错误处理
     当子线程发生恐慌时, 不会影响到其他线程, 恐慌不会在线程间传播. 当子线程发生
     错误时, 因为 Rust 基于返回值的错误处理机制, 也让跨线程错误处理变得非常方便.
     ~std::thread::JoinHandle~ 实现的 ~join()~ 方法会返回 ~Result<T>~, 当子线程
     内部发生恐慌时, 该方法会返回 ~Err~, 但是通常不会对此类 ~Err~ 进行处理, 而是
     直接使用 ~unwrap()~ 方法, 如果获取到合法的结果, 则正常使用; 若是 ~Err~, 则
     故意让父线程也发生恐慌, 这样就可以把子线程的恐慌传播到父线程, 及早发现问题.

     但是如果线程在获得锁之后发生恐慌, 则称这种情况为 "*中毒(Posion)*".

     使用 ~is_poisoned()~ 方法来查看获得互斥锁的子线程是否发生了恐慌.
     发生恐慌后, ~mutex.lock()~ 的 ~Err~ 会返回 ~PoisonError<T>~ 类型, 提供
     ~get_ref()~ 和 ~get_mut()~ 方法可以得到其内部包装的 ~T~ 类型.

**** 死锁
     当主线程一直持有互斥体的锁时, 将会导致所有的子线程阻塞. 同时, ~main~ 主线程
     还在等待子线程完成任务, 造成了死锁.

**** 读写锁(RwLock)
     在 ~std::sync~ 模块中还提供了另外这一种锁: *读写锁(~RwLock<T>~)*. 与
     ~Mutex<T>~ 十分类似, 不同点在于, ~RwLock<T>~ 对线程进行 *读者(Reader)* 和
     *写者(Writer)* 的区分, 不像 ~Mutex<T>~ 只能独占访问. 该锁支持多个读线程和一
     个写线程, 其中读线程只允许进行只读访问, 而写线程只能进行独占写操作. 只要线
     程没有拿到写锁, ~RwLock<T>~ 就允许任意数量的读线程获得读锁. 和 ~Mutex<T>~
     一样, ~RwLock<T>~ 也会因为恐慌而 "中毒".

     
     使用 ~read()~ 方法来获取读锁, 使用 ~write()~ 方法来获取写锁. *读锁和写锁妖
     使用显式作用域块隔离开*, 这样的话, 读锁或写锁才能在离开作用域之后自动释放;
     否则会引起死锁, 因为 *读锁和写锁不能同时存在*.
*** 屏障和条件变量
    Rust 除支持互斥锁和读写锁之外, 还支持 *屏障(Barrier)* 和 *条件变量(Condition
    Variable)*.

    屏障的用法和互斥锁类似, 它可以通过 ~wait()~ 方法再某个点阻塞全部进入临界区的
    线程.

    屏障的 ~wait()~ 方法会阻塞当前线程, 一般用于实现线程同步.

    *条件变量* 跟屏障有些类似, 但它不会阻塞全部线程, 而是满足指定条件之前阻塞某
    一个得到互斥锁的线程.

    *注意*: *在运行中每个条件变量每次只能和一个互斥体一起使用*. 在有些线程需要获
    取某个状态陈力的情况下, 如果单独使用互斥锁会比较浪费系统组员, 因为只有多次出
    入临界区才能获取到某个状态的信息. 此时就可以配合使用条件变量, 当状态成立时通
    知互斥体就可以, 因此减少了系统资源的浪费.
*** 原子类型
    互斥锁, 读写锁等同步原语确实可以满足基本的线程安全需求, 但是有时候使用锁会影
    响相连, 甚至存在死锁的风险, 因此引入了原子类型.

    原子类型内部封装了编程语言和操作系统的 "契约", 基于此契约来实现一些自带原子
    操作的类型, 而不需要对其使用锁来保证原子性, 从而实现无锁(Lock-Free)并发编程.
    这个契约就是 *多线程内存模型*. Rust 的多线程内存模型借鉴于 C++ 11, 它保证了
    多线程并发的顺序一致性, 不会因为底层的各种优化重排行为而失去原子性.

    对于开发者来说, 如果说编程语言提供的锁机制属于 "白盒" 操作的话, 那么原子类型
    就属于 "黑盒" 操作. 有如下操作:
    - *Load*: 表示从一个原子类型内部读取值
    - *Store*: 表示往一个原子类型内部写入值

    各种提供原子 "读取-修改-写入" 的操作:
    - *CAS(Compare-And-Swap)*: 表示比较并交换
    - *Swap*: 表示原子交换操作
    - *Compare-Exchange*: 表示比较/交换操作
    - *Fetch-**: 表示 fetch_add、fetch_sub、fetch_and 和 fetch_or 等一系列原子的加
      减或逻辑运算
    - 其他

    通过上面原子类型 "对外公开" 的一系列原子操作, 就可以从外部来控制多线程内存模
    型内部的顺序一致性, 从而不用担心底层各种指令重排会导致线程不安全的问题.

**** Rust 标准库中提供的原子类型
     在 Rust 标准库 ~std::sync::atomic~ 模块中暂时提供了 4 个稳定的原子类型, 分
     别是 ~AtomicBool~, ~Atomiclsize~, ~AtomicPtr~ 和 ~AtomicUsize~, 另外还有很
     多基本的原子类型会逐步稳定. 这些原子类型均提供了一系列原子操作.

     原子类型虽然可以保证原子性, 但它自身不提供在多线程中共享的方法, 所以需要使
     用 ~Arc<T>~ 将其跨线程共享.

     "自旋" 就是指在 *语义上表示这种不断循环获取锁状态的行为*.
`
**** 内存顺序
     原子类型除基本的原子操作之外, 还提供了内存顺序参数. 虽然每个原子类型对开发
     者而言是一个 "黑盒", 但也可以通过提供内存顺序参数来控制底层线程执行顺序的参
     数. 控制内存顺序实际上就是控制底层线程同步, 以便消除底层因为编译器优化或指
     令重排而引发的竞态条件.

     在 ~std::sync::atomic::Ordering~ 模块中定义了 Rust 支持的 5 种内存顺序.
     #+begin_src rust
       #[stable(feature = "rust1", since = "1.0.0")]
       #[derive(Copy, Clone, Debug, Eq, PartialEq, Hash)]
       #[non_exhaustive]
       pub enum Ordering {
           #[stable(feature = "rust1", since = "1.0.0")]
           Relaxed,
           #[stable(feature = "rust1", since = "1.0.0")]
           Release,
           #[stable(feature = "rust1", since = "1.0.0")]
           Acquire,
           #[stable(feature = "rust1", since = "1.0.0")]
           AcqRel,
           #[stable(feature = "rust1", since = "1.0.0")]
           SeqCst,
       }
     #+end_src

     - *排序一致性顺序*: ~Ordering::SeqCst~
     - *自由顺序*: ~Ordering::Relaxed~
     - *获取 - 释放顺序*: ~Ordering::Release~, ~Ordering::Acquire~ 和
       ~Ordering::AcqRel~.

     Rust 支持的 5 种内存顺序与其底层的 LLVM 支持的内存顺序是一致的.

     *排序一致性顺序*: 是最直观、最简单的内存顺序, 它规定使用排序一致性顺序, 也就
     是指定 ~Ordering::SeqCst~ 的原子操作, 都必须先存储(store)再加载(load). 这就
     意味着: 多线程环境下, 所有的原子写操作都必须在读操作之前完成. 通过这种规定,
     就强行指定了底层多线程的执行顺序, 从而保证了多线程中所有操作的全局一致性.
     但是简单是要付出代价的, 这种方式需要对 *所有的线程进行全局同步*, 这就存在性
     能损耗.

     *自由顺序*: 正好是排序一致性顺序的对立面, 顾名思义, 它完全不会对线程的顺序
     进行干涉. 也就是说, 线程只进行原子操作, 但线程之间会存在竞态条件. 使用这种
     内存顺序是比较危险的, 只有在明确了解当前使用场景且必须使用它的情况下(eg: 只
     有读操作), 才可使用自由顺序.

     *获取 - 释放顺序*: 是除排序一致性之外的优先选择. 这种内存顺序并不会对全部的
     线程进行统一强制性的执行顺序要求. 在该内存顺序中, ~store~ 代表释放(Release)
     语义, 而 ~load~ 代表获取(Acquire)语义, 通过这两种操作的协作实现线程同步. 其
     中, ~Ordering::Release~ 表示使用该顺序的 ~store~ 操作, 之前所有的操作对于使
     用 ~Ordering::Acquire~ 顺序的 ~load~ 操作都是可见的; 反之亦然, 使用
     ~Ordering::Acquire~ 顺序的 ~load~ 操作对于使用 ~Ordering::Release~ 的
     ~store~ 操作都是可见的; ~Ordering::AcqRel~ 代表读时使用 ~Ordering::Acquire~
     顺序的 ~load~ 操作, 写时使用 ~Ordering::Release~ 顺序的 ~store~ 操作.

     获取 - 释放顺序虽然不像排序一致性顺序那样对全局线程统一排序, 但是它让每个线
     程都能按固定的顺序执行. 

     在日常开发的选择和底层硬件环境也有关系. 一般情况下建议使用
     ~Ordering::SeqCst~. 在需要性能优化的情况下, 先调研并发程序运行的硬件环境,
     再优先选择获取 - 释放顺序(~Ordering::Release~, ~Ordering::Acquire~ 和
     ~Ordering::AcqRel~ 按需选择). 除非必要, 否则不要使用 ~Ordering::Relaxed~.

*** 使用 Channel 进行线程间通信
    坊间流传着一局非常经典的话: *不要通过共享内存来通信, 而应该使用通信来共享内
    存*. 这句话中蕴含着一种古老的编程哲学, 那就是消息传递, 通过消息传递的手段可
    以降低由共享内存而产生的耦合.

    基于消息通信的并发模型主要有 2 种: *Actor* 模型和 *CSP* 模型. Actor 模型的
    代表语言是 Erlang, 而 CSP 模型的代表语言是 Golang. 这两种并发模型的区别如
    下:

    - 在 Actor 模型中, 主角是 Actor, Actor 之间直接发送、接收消息
    - 在 Actor 模型中, Actor 之间是直接通信的; 而在 CSP 模型中, 依靠 Channel 来
      通信
    - Actor 模型的耦合程序要高于 CSP 模型, 因为 CSP 模型不关注消息发送者和接受
      者.

    这两种模型都存在了很多年, 随着 Golang 语言的出现, CSP 模型再次回到开发者的
    视线中. Rust 标准库也选择实现了 CSP 并发模型.  

**** CSP 并发模型
     CSP(Communicating Sequential Processes, 通信顺序进程)是一个精确描述并发的
     数学理论, 基于该理论构建的并发程序不会出现常见的问题, 并且可以得到数学证明.
     CSP 对程序中每个阶段所包含对象的行为进行精确的指定和验证, 它对并发程序的设
     计影响深远.

     *CSP 模型* 的基本构造是 *CSP 进程* 和 *通信通道*. 注意: 此处 CSP 进程是并
     发模型中的概念, 不是操作系统中的进程. 在 CSP 中每个事件都是进程, 进程之间
     没有直接交互, 只能通过通信通道来交互. CSP 进程通常是匿名的, 通信通道传递消
     息通常使用同步方式.

     CSP 理论在很多语言中得以实现, 包括 Java、Golang 和 Rust 等. 在 Rust 的实现
     中, 线程就是 CSP 进程, 而通信通道就是 Channel. 在 Rust 标准库的
     ~std::sync::mpsc~ 模块中为线程提供了 Channel 机制, 其具体实现实际上是一个
     *多生产者单消费者(Multi-Producer-Single-Consumer, MPSC)* 的 先进先出(FIFO)
     队列. 线程通过 Channel 进行通信, 从而可以实现无锁并发.

**** 生产者消费者模式与 Channel
     生产者消费者模式是指通过一个中间层来解决数据生产者和消费者之间的耦合问题.
     生产者和消费者之间不直接通信, 而是分别与中间层进行通信. 生产者向中间层生产
     数据, 消费者从中间层获取数据进行消费, 这样就巧妙地平衡了生产者和消费者对数
     据的处理能力.

     一般情况下, 使用一个 FIFO 队列来充当中间层. 在多线程环境下, 生产者就是生产
     数据的线程, 消费者就是消费数据的线程. Rust 实现的是多生产者单消费者模式.

     该 FIFO 队列就是 CSP 模型中的 Channel 的具体实现, 在标准库
     ~std::sync::mpsc~ 模块中定义了以下三种类型的 CSP 进程:

     - *Sender*: 用于发送异步消息
     - *SyncSender*: 用于发送同步消息
     - *Receiver*: 用于接收消息

     Rust 中的 Channel 包括两种类型:
     - *异步无界 Channel*, 对应于 channel 函数, 会返回 *(Sender, Receiver)* 元
       组. 该 Channel 发送消息是异步的, 并且不会阻塞. *无界*, 是指理论上缓冲区
       是无限的.
     - *同步有界 Channel*, 对应于 sync_channel 函数, 会返回 *(SyncSender,
       Receiver)* 元组. 该 Channel 可以预分配具有固定大小的缓冲区, 并且发送消息
       是同步的, 当缓冲区满时会阻塞消息发送, 知道有可用的缓冲空间. 当该 Channel
       缓冲区大小为 0 时, 就会变成一个 "点", 在这种情况下, Sender 和 Receiver
       之间的消息传递是原子操作.

     Channel 之间的发送或接受操作都会返回一个 Result 类型用于错误处理. 当
     Channel 发生意外时会返回 Err, 所以通常使用 ~unwrap()~ 在线程间传播错误, 及
     早发现问题.

     只有两个线程通信的 Channel, 叫做 *流通道(Streaming Channel)*. 在流通道内部,
     实际上 Rust 会默认使用 *单生产者单消费者队列(SPSC)* 来提升性能.

     多生产者单消费者的 Channel, 叫做 *共享通道(Sharing Channel)*.
        
**** Channel 死锁
     并不是没有锁就不会发生死锁的行为.

     当使用 *共享通道时*, ~tx~ 不 ~drop()~, 主线程 ~rx.iter()~ 会一直等待.

     当使用 *流通道时*, 发送端 ~tx~ 在离开作用域之后会自动调用析构函数
     ~drop()~, 在 ~drop()~ 中会调用 ~tx~ 内部的 ~drop_channel()~ 方法来 *断开*
     (DISCONNECT) Channel. 

     当 Channel 是共享通道时, 在 for 循环中调用 ~tx~ 的 ~clone()~ 方法; 当
     Channel 是流通道时, ~tx~ 在离开子线程作用域之后通过析构函数就可以断开
     Channel. 

     之所以存在这样的区别, 在于共享通道的流底层的构造有所不同. 流通道底层自动使
     用 SPSC 队列来优化性能, 因为流通道只是用于两个线程之间的通信. 但是共享通道
     底层使用的还是 MPSC 队列, 在析构行为上比流通道略为复杂. 所以在通常的开发过
     程中, 要注意这两类 Channel 的区别.

     在底层不管是 SPSC 还是 MPSC 队列, 甚至是同步 Channel 使用的内置独立的队列,
     都是 *基于链表实现的*. 使用链表的好处就是可以提升性能. 在生产数据时, 只需
     要在链表头部添加新的元素即可; 在消费数据时, 只需要从链表尾部取元素即可.

**** 利用 Channel 模拟工作量证明
     接下来, 我们使用 Channel 来解决一个来自数据货币领域的问题. 众所周知, 比特
     币开创了数字货币时代, 它不仅仅革新了金融领域, 更重要的是它带来了区块链的概
     念. 区块链采用密码学的方法来保证已有的数据不可篡改, 采用共识算法为新增的数
     据达成共识, 这完全是与生俱来的且去中心化的 "公信力". 而信任是人类社会一切
     交易的前提, 于是, 这种借助于密码学和算法取得信任的区块链技术, 正逐渐成为当
     前互联网上各种商业信用体的基础设施.

     在比特币中, 最流行的一个词就是 "挖矿", 就是指 *工作量证明(Proof of Work,
     PoW)*.

     该术语最早被用于防范拒绝服务攻击等领域. 下面简单用一个示例来说明 *工作量证
     明机制的基本原理*.

     - 给定一个字符串或数字, eg: 42
     - 给定一个工作目标: 找到另外一个数字, 要求该数字和 42 相乘后的结果, 经过
       Hash 函数处理后, 满足得到的加密字串以 "00000" 开头. 可以通过对 "00000"
       增加或减少 0 的个数来控制查找的难度.
     - 为了找到这个数字, 需要从数字 1 开始递增查找, 查找到满足条件的数字.

     要找到这个数字, 就需要大量的计算. 在这个示例中, 数字期望的计算次数就是 "工
     作量", 重复多次验证是否满足条件就是 "工作量证明", 这是一个符合统计学规律的
     概率事件. 当然, 比特币和以太坊中真实的工作量证明算法比这个示例更复杂一些,
     但原理是相似的.

     现在, 使用 Rust 来实现上述示例描述哦模拟工作量证明过程. *代码结构设计如下*:
     - 使用多线程来加速查找过程
     - 将查找到打的符合条件的数字和加密字串通过 Channel 传递到另外一个线程中并
       输出.

     为简单器件, 将整个代码都写到同一个文件中. 接下来, 使用 ~cargo new --bin
     pow~ 创建一个新项目. 实现此过程中, 需要用到两个第三方包 -- 用来求 Hash 值
     的 rust-crypto 和用来方便迭代的 itertools.
        
     整个实现过程中需要注意一下几个地方:
     - 如何正确地分离生产线程和消费线程?
     - 如何正确地划分并发任务?
     - 如何正确地识别临界区, 以及如何正确地使用原子类型及其内存顺序?

*** 内部可变性探究
    在 Rust 提供的并发编程工具中, 基本都支持内部可变性, 在行为上与 ~Cell<T>~,
    ~RefCell<T>~ 比较相似.
    
    ~Mutex~ 源码实现
    #+begin_src rust
      #[stable(feature = "rust1", since = "1.0.0")]
      #[cfg_attr(not(test), rustc_diagnostic_item = "mutex_type")]
      pub struct Mutex<T: ?Sized> {
          // 包装了用于调用底层操作系统 API 的 `sys::MovableMutex`
          inner: sys::MovableMutex,
          // 用于标记该锁是否已 "中毒"
          poison: poison::Flag,
          // 锁包含的数据
          data: UnsafeCell<T>,
      }
    #+end_src

    由上可知, 内部可变性是由 ~UnsafeCell<T>~ 提供的.

    继续查看其他源码实现:
    ~Cell<T>~, ~RefCel<T>~, ~RwLock<T>~ 等源码实现:
    #+begin_src rust
      #[stable(feature = "rust1", since = "1.0.0")]
      #[repr(transparent)]
      pub struct Cell<T: ?Sized> {
          value: UnsafeCell<T>,
      }
      #[stable(feature = "rust1", since = "1.0.0")]
      pub struct RefCell<T: ?Sized> {
          borrow: Cell<BorrowFlag>,
          value: UnsafeCell<T>,
      }
      #[stable(feature = "rust1", since = "1.0.0")]
      pub struct RwLock<T: ?Sized> {
          inner: Box<sys::RWLock>,
          poison: poison::Flag,
          data: UnsafeCell<T>,
      }
      #[cfg(target_has_atomic_load_store = "8")]
      #[stable(feature = "rust1", since = "1.0.0")]
      #[repr(C, align(1))]
      pub struct AtomicBool {
          v: UnsafeCell<u8>,
      }
      #[stable(feature = "rust1", since = "1.0.0")]
      pub struct Sender<T> {
          inner: UnsafeCell<Flavor<T>>,
      }
      #[stable(feature = "rust1", since = "1.0.0")]
      pub struct Receiver<T> {
          inner: UnsafeCell<Flavor<T>>,
      }
    #+end_src

    由上可知, 这些拥有内部可变性的结构体都是基于 ~UnsafeCell<T>~ 实现的.

    继续查看 ~UnsafeCell<T>~ 的源码实现:
    #+begin_src rust
      #[lang = "unsafe_cell"]
      #[stable(feature = "rust1", since = "1.0.0")]
      #[repr(transparent)]
      #[repr(no_niche)] // rust-lang/rust#68303.
      pub struct UnsafeCell<T: ?Sized> {
          value: T,
      }
      #[stable(feature = "rust1", since = "1.0.0")]
      // 实现了 `!Sync`, 所以单独使用该类型并不能保证线程安全
      impl<T: ?Sized> !Sync for UnsafeCell<T> {}
      impl<T: ?Sized> UnsafeCell<T> {
          #[inline]
          #[stable(feature = "rust1", since = "1.0.0")]
          #[rustc_const_stable(feature = "const_unsafecell_get", since = "1.32.0")]
          // 将不可变借用转为可变的原生指针
          pub const fn get(&self) -> *mut T {
              // 先转为 *const T, 再转为 *mut T
              self as *const UnsafeCell<T> as *const T as *mut T
          }
          #[inline]
          #[unstable(feature = "unsafe_cell_get_mut", issue = "76943")]
          pub fn get_mut(&mut self) -> &mut T {
              unsafe { &mut *self.get() }
          }
      }
    #+end_src

    ~UnsafeCell<T>~ 只是一个泛型结构体, 它属于 *语言项(Lang Item)*, 所以编译器会
    对它进行某种特殊的照顾.

    关于 ~get()~ 方法: 
    一般来说, 在 Rust 中将不可变借用转换为可变借用属于 *未定义行为*, 编译器不允
    许开发者随意对这两种引用进行相互转换. 但是, ~UnsafeCell<T>~ 是唯一的例外. 这
    也是 ~UnsafeCell<T>~ 属于语言项的原因, 它属于 Rust 中将不可变转换为可变的唯
    一合法渠道, 对于使用了 ~UnsafeCell<T>~ 的类型, 编译器会关闭相关的检查.

    因此, 在上述各种拥有内部可变性的容器内部均使用了 ~UnsafeCell<T>~, 不会违反
    Rust 的编译器安全检查.
    
*** 线程池
    在实际应用中, 多线程并发更常用的方式是使用线程池. 线程虽然比进程轻量, 但如果
    每次处理任务都要重新创建线程的话, 就会导致线程过多, 从而带来更多的创建和调度
    的开销. 采用线程池的方式, 不仅可以实现对线程的复用, 避免多次创建、销毁线程的
    开销, 而且还能保证内核可以被充分利用.

    实现一个线程池需要考虑以下几点:
    - 工作线程: 用于处理具体任务的线程
    - 线程池初始化: 即通过设置参数指定线程池的初始栈大小、名称、工作线程数等
    - 待处理任务的存储队列: 工作线程数是有限的, 对于来不及处理的任务, 需要暂时保
      存到一个队列中.
    - 线程池管理: 即管理线程池中的任务数和工作线程的状态. eg: 在没有空闲工作线程
      时则需要等待, 或者在需要时主线程等待所有任务执行完毕.

    接下来参考第三方包 *[[https://crates.io/crates/threadpool][threadpool]]* 的实现, 来说明如何使用 Rust 标准库中提供的并
    发工具来实现一个简单的线程池.

    - 线程池: 通过创建一个线程池结构体来控制线程池的初始化. 为此结构体实现
      Builder 模式, 定制初始化参数, 并且实现工作线程的方法.
    - 待处理任务队列: 使用无界队列 ~mpsc::channel~, 缓存待处理的任务
    - 线程池管理: 使用原子类型对工作任务状态进行计数, 达到管理的目的.

    使用 ~cargo new --bin thread_pool~ 创建一个新项目, 添加 ~nums_cpus~ 的依赖
    ~num_cpus~ 依赖可以识别当前运行的计算机中 CPU 的个数, 将其作为线程池默认的工
    作线程数.

*** 使用 Rayon 执行并行任务
    *Rayon* 是一个第三方包, 使用它可以轻松地将顺序计算转换为安全的并行计算, 并且
    保证无数据竞争. Rayon 提供了 2 种使用方法:

    - *并行迭代器*: 即可以并行执行的迭代器
    - *. ~join()~ 方法*: 可以并行处理递归或分治风格的问题

    使用 ~join()~ 方法 *不一定包保证并行执行闭包*, Rayon 底层使用线程池来执行任
    务, 如果工作线程被占用, Rayon 会选择顺序执行. Rayon 的并行能力基于一种叫做
    *工作窃取(Work-Stealing)* 的技术, 线程池分钟的每个线程都有一个互不影响的任务
    队列(双端队列), 线程每次都从当前任务队列的头部取出一个任务来执行. 如果某个线
    程对应的队列已空并且处于空闲状态, 而其他线程的队列中还有任务需要处理, 但是该
    线程处于工作状态, 那么空闲的线程就可以从其他线程的队列尾部取一个任务来执行.
    这种行为表现就像空间的线程去偷工作中的线程任务一样, 所以叫做 "工作窃取".

    Rayzon 的更多细节, 参考 [[https://github.com/rayon-rs/rayon/tree/master/rayon-demo][rayon-demo]]
