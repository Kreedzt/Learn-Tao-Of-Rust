* 字符串与集合类型
  数据结构是计算机存储和组织数据的方式. 对于不同的场景, 精心选择的数据结构可以带
  来更高的运行效率或存储效率. 通常, 通过确定数据结构来选择相应的算法, 也可能通过
  算法来选择数据结构, 不管是哪种情况, 选择合适的数据结构都相当重要.

  程序中最常用的三大数据结构是字符串、数组和映射. 字符串是特殊的线性表, 是由 0 个
  或多个字符组成的有限序列. 但字符串和数组、映射的区别在于, 字符串是被作为一个整
  体来关注和使用的; 而数组和映射关注最多的是其中的元素及它们之间的关系. 所以, 数
  组和映射也被称为集合类型. Rust 作为一门现代高级语言, 也自然为这三大数据结构提
  供了丰富的操作支持.

** 字符串
   在编程中字符串具有非常重要的地位. 计算机底层只存储 0 和 1 这两个数字, 如果想
   让计算机处理各种字符串, 就必须建立字符和特定数字的一一映射关系. eg: 想让计算
   机存储字符 A, 则存储二进制数 0100_0001, 在读取的时候, 再将 0100_0001 显示为字
   符串 A, 这样就将字符 A 和 0100_0001 建立了一一映射关系. 这种方案, 就叫做 *字
   符编码* (Character Encoding).

*** 字符编码
    最早的字符编码就是常见的 ASCⅡ 编码. 因为计算机起源于美国, 美国是以英语为母语
    的国家, 所以 ASCⅡ 码表中只记录了英文字母大小写和一些常用的基本符号, 并使用 0
    ~ 127 的数字来表示它们. 最大的数字 127 的二进制数是 1111111, 所以用 1 字节(8
    比特位) 足以表示全部的 ASCⅡ 编码.

    随着计算机的普及, 出现了很多编码标准, GB2312 是我国基于 ASCⅡ 编码进行中文扩
    充以后产生的, 可以表示 6000+ 个汉子. 之后出现了 GBK 编码, 包括 GB2312 的所有
    汉字外, 又扩充了近 2 万个汉子. 再后来, 为了兼容少数民族语言,  又扩充成
    GB18030 编码. 而与此同时, 其他国家也都分别创造了属于自己语言的字符编码标准.
    这样带来的后果就是:　如果想同时显示多个国家的文字，　就必须在计算机中安装多
    套字符编码系统，　这就带来了诸多不便.

    为了解决这个问题, 国际标准化组织指定了通用的多字节编码字符集, 也就是 Unicode
    字符集. 该字符集相当于一张表, 其中包含了世界上所有语言中可能出现的字符, 每个
    字符对应一个非负整数, 该数字称为 *码点(Code Point)*. 这些码点也分为不同的类
    型, 包括 *标量值(Scala Value)* 、代理对码点、非字符码点、保留码点、和私有码
    点. 其中标量值最常用, 它是指实际存在对应字符的码位, 其范围是 0x0000 ~ 0xD7FF
    和 0xE000 ~ 0x10FFFF 两段. Unicode 字符集只规定了字符所对应的码点, 却没有指
    定如何存储. 如果直接存储码位, 则太耗费时间了, 因为 Unicode 字符集的每个字符
    都占 4 字节, 传输效率非常低. 虽然 Unicode 字符集解决了字符通用的问题, 但是必
    须寻求另外一种存储方式, 在保证 Unicode 字符集通用的情况下更加节约流量和硬盘
    空间. 这种存储方式就是 *码元(Code Unit)* 组成的序列.

    | \                | 英文字符 A | 中文道         | emoji:smile:        |
    |------------------+------------+----------------+---------------------|
    | Code Point       |     U+0x41 | U+9053         | U+1F600             |
    | UTF-8 Code Point |       0x41 | 0xE9 0x81 0x93 | 0xF0 0x9F 0x98 0x84 |
    | Byte             |          1 | 3              | 4                   |

    码元是指用于处理和交换编码文本的最小比特组合. eg: 计算机处理字符的最小单位 1
    字节就是一个码元. 通过将 Unicode 标量值和码元序列建立一一映射关系, 就构成了
    码表. 在 Unicode 中一共有 3 种这样的字符编码表: UTF-8, UTF-16 和 UTF-32, 它
    们正好对应了 1 字节, 2 字节和 4 字节的码元. 对于 UTF-16 和 UTF-32 来说, 因为
    它们的码元分别是 2 字节和 4 字节, 所以就得考虑字节节序问题; 而对于 UTF-8 来
    说, 一个码元只有 1 字节, 所以不存在字节序问题, 可以直接存储.

    UTF-8 是以 1 字节为编码单位的可变长编码, 它根据一定的规则将码位编码为 1 ~ 4
    字节, 如下所示:
    | Unicode 范围      | UTF-8 编码(1-4 字节)                |
    |-------------------+-------------------------------------|
    | U+0000 ~ U+-007F  | 0XXXXXXX                            |
    | U+0800 ~ U+07FF   | 110XXXXX 10XXXXXX                   |
    | U+0800 ~ U+FFFF   | 1110XXXX 10XXXXXX 10XXXXXX          |
    | U+10000 ~ U+1FFFF | 11110XXX 10XXXXXX 10XXXXXX 10XXXXXX |

    UTF-8 编码规则大致如下：
    - 当一个字符在 ASCⅡ 码的范围(兼容 ASCⅡ 码)内时, 就用 1 字节表示, 因为 ASC Ⅱ
      码中的字符最多使用 7 个比特位, 所以前面需要补 0.
    - 当一个字符占用了 n 字节时, 第一字节的前 n 位设置为 1, 第 n+1 位 设置为 0,
      后面字节的前 2 位设置为 10.

    以 "道" 举例, 它的码位是 U+9053, 相应的二进制表示为 1001_0000_0101_0011, 按
    上述 UTF-8 编码规则进行编码, 则变为字节序列 1110_1001_10_000001_10_010011,
    用十六进制表示的话, 就是 0xE90x810x93.

    像这种将 Unicode 码位转换为字节序列的过程，　就叫做 *编码(Encode)*; 反过来,
    将编码字节序列转变为字符集中码位的过程, 就叫做 *解码(Decode)*.

    UTF-8 编码的好处就是在实际传输过程中其占据的长度是不固定的, 在保证 Unicode
    通用性的情况下避免了流量和空间的浪费, 而且还保证了传输过程中不会错判字符. 正
    因如此, UTF-8 才能被广泛应用于互联网中.

    
*** 字符
    Rust 使用 char 类型表示单个字符. char 雷神使用整数值与 Unicode 标量值一一对
    应.

    在 Rust 中每个 char 类型的字符都代表一个有效的 u32 类型的整数, 但不是每个
    u32 类型的整数都能代表一个有效的字符. 因为并不是每个整数都属于 Unicode 标量
    值.

    为了能够存储任何 Unicode 标量值, Rust 规定 *每个字符都占 4 字节*.

    将字符串转换为字符串时, 要注意字节长度. 可以通过内建的 ~len_utf8()~ 方法获取
    UTF-8 编码的字节长度.

    *注意*: 只有包含单个 Unicode 标量值(实际码位)的才能被声明为字符.
